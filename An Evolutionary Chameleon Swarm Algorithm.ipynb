{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11133625,"sourceType":"datasetVersion","datasetId":6943977}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# An Evolutionary Chameleon Swarm Algorithm based Network for 3D Medical Image Segmentation ","metadata":{"tags":[]}},{"cell_type":"code","source":"import torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA device count: {torch.cuda.device_count()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n    # Try a simple GPU operation\n    x = torch.rand(5, 3).cuda()\n    print(f\"Tensor device: {x.device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:45:43.028864Z","iopub.execute_input":"2025-05-01T04:45:43.029080Z","iopub.status.idle":"2025-05-01T04:45:43.041585Z","shell.execute_reply.started":"2025-05-01T04:45:43.029058Z","shell.execute_reply":"2025-05-01T04:45:43.040111Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.5.1+cu121\nCUDA available: False\nCUDA device count: 0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:38:15.699424Z","iopub.execute_input":"2025-04-30T16:38:15.699874Z","iopub.status.idle":"2025-04-30T16:38:15.705832Z","shell.execute_reply.started":"2025-04-30T16:38:15.699839Z","shell.execute_reply":"2025-04-30T16:38:15.704866Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip3 install git+https://github.com/Project-MONAI/MONAI#egg=monai","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T17:28:36.788850Z","iopub.execute_input":"2025-04-30T17:28:36.789336Z","iopub.status.idle":"2025-04-30T17:31:45.767914Z","shell.execute_reply.started":"2025-04-30T17:28:36.789298Z","shell.execute_reply":"2025-04-30T17:31:45.766518Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Cloning https://github.com/Project-MONAI/MONAI to /tmp/pip-install-jv6oygzi/monai_38ae9478a2504f138dcaaeb5da690b7a\n  Running command git clone --filter=blob:none --quiet https://github.com/Project-MONAI/MONAI /tmp/pip-install-jv6oygzi/monai_38ae9478a2504f138dcaaeb5da690b7a\n  Resolved https://github.com/Project-MONAI/MONAI to commit b58e883c887e0f99d382807550654c44d94f47bd\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->monai) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nBuilding wheels for collected packages: monai\n  Building wheel for monai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for monai: filename=monai-1.4.1rc1+46.gb58e883c-py3-none-any.whl size=2658851 sha256=306a58a4e8b35f8fde6e0bdce7251822e742341e9c6cbb3318d5e8df4e3fdad2\n  Stored in directory: /tmp/pip-ephem-wheel-cache-c0wu8bty/wheels/ae/df/85/e1529c65c7b6d24f94fb29018f2e6a19809d416ee64044d71f\nSuccessfully built monai\nInstalling collected packages: monai\nSuccessfully installed monai-1.4.1rc1+46.gb58e883c\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip3 install monai[nibabel,skimage]","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T18:08:02.426604Z","iopub.execute_input":"2025-04-30T18:08:02.427175Z","iopub.status.idle":"2025-04-30T18:08:07.360961Z","shell.execute_reply.started":"2025-04-30T18:08:02.427132Z","shell.execute_reply":"2025-04-30T18:08:07.359707Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai[nibabel,skimage] in /usr/local/lib/python3.10/dist-packages (1.4.1rc1+46.gb58e883c)\nRequirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from monai[nibabel,skimage]) (2.5.1+cu121)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai[nibabel,skimage]) (1.26.4)\nRequirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from monai[nibabel,skimage]) (5.3.2)\nRequirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from monai[nibabel,skimage]) (0.25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai[nibabel,skimage]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai[nibabel,skimage]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai[nibabel,skimage]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai[nibabel,skimage]) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai[nibabel,skimage]) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.24->monai[nibabel,skimage]) (2.4.1)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (1.13.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (3.4.2)\nRequirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (11.0.0)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (2024.12.12)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->monai[nibabel,skimage]) (0.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai[nibabel,skimage]) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai[nibabel,skimage]) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai[nibabel,skimage]) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai[nibabel,skimage]) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->monai[nibabel,skimage]) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->monai[nibabel,skimage]) (1.3.0)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->monai[nibabel,skimage]) (5.13.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->monai[nibabel,skimage]) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.24->monai[nibabel,skimage]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.24->monai[nibabel,skimage]) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai[nibabel,skimage]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai[nibabel,skimage]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.24->monai[nibabel,skimage]) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install thop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T18:08:09.407641Z","iopub.execute_input":"2025-04-30T18:08:09.408092Z","iopub.status.idle":"2025-04-30T18:08:14.577572Z","shell.execute_reply.started":"2025-04-30T18:08:09.408056Z","shell.execute_reply":"2025-04-30T18:08:14.576184Z"}},"outputs":[{"name":"stdout","text":"Collecting thop\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (3.0.2)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop\nSuccessfully installed thop-0.1.1.post2209072238\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\"\"\"importing modules\"\"\"\nfrom monai.transforms import (\n    AsDiscrete,\n    AsDiscreted,\n    EnsureChannelFirstd,\n    Compose,\n    CropForegroundd,\n    LoadImaged,\n    Orientationd,\n    RandCropByPosNegLabeld,\n    SaveImaged,\n    ScaleIntensityRanged,\n    Spacingd,\n    RandAffined,\n    Invertd,\n)\nimport os\nimport csv\nimport glob\nimport time\nimport torch\nimport pandas\nimport shutil\nimport tempfile\nimport numpy as np\nfrom thop import profile\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary\nfrom monai.losses import DiceLoss\nfrom monai.config import print_config\nfrom monai.networks.layers import Norm\nfrom monai.apps import download_and_extract\nfrom monai.handlers.utils import from_engine\nfrom monai.utils import first, set_determinism\nfrom monai.inferers import sliding_window_inference\nfrom monai.metrics import DiceMetric, MeanIoU, compute_roc_auc\nfrom monai.data import CacheDataset, DataLoader, Dataset, decollate_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T18:08:18.263970Z","iopub.execute_input":"2025-04-30T18:08:18.264398Z","iopub.status.idle":"2025-04-30T18:08:49.177781Z","shell.execute_reply.started":"2025-04-30T18:08:18.264363Z","shell.execute_reply":"2025-04-30T18:08:49.176020Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from monai.networks import blocks\n\ndef CONV(s, i, o, k, n, a, d):\n    return blocks.Convolution(spatial_dims=s, in_channels=i, out_channels=o, kernel_size=k, norm=n, act=a, dropout=d)\n\n\n#Block1\ndef UBB(s, i, o, k, n, a, d):\n\treturn blocks.UnetBasicBlock(spatial_dims=s, in_channels=i, out_channels=o, kernel_size=k, stride=1, norm_name=n, act_name=a, dropout=d)\n\n#Block2\ndef URB(s, i, o, k, n, a, d):\n\treturn blocks.UnetResBlock(spatial_dims=s, in_channels=i, out_channels=o, kernel_size=k, stride=1, norm_name=n, act_name=a, dropout=d)\n\n#Block3\ndef RB(s, i, o, k, n, a, d):\n\treturn blocks.ResBlock(spatial_dims=s, in_channels=i, norm=n, kernel_size=k, act=a)\n\n#Block4\ndef SASPP(s, i, o, k, n, a, d):\n    return blocks.SimpleASPP(spatial_dims=s, in_channels=i, conv_out_channels=int(o/2), kernel_sizes=[k,k], dilations=[1,1], norm_type=n, acti_type=a, bias=False)\n\n#Block5\ndef SERB(s, i, o, k, n, a, d):\n\treturn blocks.SEResNetBottleneck(spatial_dims=s, inplanes=i, planes=4, groups=4, reduction=2, stride=1, downsample=None)\n#outchannels=16\n\n#Block6\ndef P3AB(s, i, o, k, n, a, d):\n\treturn blocks.P3DActiConvNormBlock(in_channel=i, out_channel=o, kernel_size=k, padding=1, act_name=a, norm_name=n)\n\n#Block7\ndef RRCB(s, i, o, k, n, a, d):\n    return blocks.RegistrationResidualConvBlock(spatial_dims=s, in_channels=i, out_channels=i, num_layers=2, kernel_size=k)\n\n#Block8\ndef UrPUB(s, i, o, k, n, a, d):\n\treturn blocks.UnetrPrUpBlock(spatial_dims=s, in_channels=i, out_channels=o, num_layer=1, kernel_size=k, stride=1, upsample_kernel_size=1, norm_name=n, conv_block=True, res_block=True)\n\n\n\ndef  MaxAvg(k):\n\treturn blocks.MaxAvgPool(spatial_dims=3, kernel_size=k, stride=2, padding=0, ceil_mode=True)\n\n\n\ndef  Ups(s, i, o, k, n, a, d):   #Upsample\n\treturn blocks.FactorizedIncreaseBlock(in_channel=i, out_channel=o, spatial_dims=s, act_name=a, norm_name=n) \n\ndef  Transp(s, i, o, k, n, a, d):  #conv3dtranspose\n\treturn blocks.UpSample(spatial_dims=s, in_channels=i, out_channels=o, scale_factor=2, kernel_size=None, size=None, mode='deconv', pre_conv='default', interp_mode='LINEAR', align_corners=True, bias=True, apply_pad_pool=True)  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:12.125152Z","iopub.execute_input":"2025-03-30T15:20:12.126145Z","iopub.status.idle":"2025-03-30T15:20:12.136994Z","shell.execute_reply.started":"2025-03-30T15:20:12.126111Z","shell.execute_reply":"2025-03-30T15:20:12.136178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom torch import nn\n\nclass Block(nn.Module):\n    def __init__(self, bn, inc, outc, kernel, norm, act, dr):\n        super().__init__()\n        self.bn = bn\n        self.inc = inc\n        self.outc = outc\n        self.kernels = kernel\n        self.norms = norm\n        self.acts = act\n        self.do = dr\n        \n        self.ubb = UBB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.urb = URB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.rb = RB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.conv = CONV(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.saspp = SASPP(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do) \n        self.serb = SERB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.conv1 = CONV(s=3, i=16, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.p3ab = P3AB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.rrcb = RRCB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        self.urpub = UrPUB(s=3, i=self.inc, o=self.outc, k=self.kernels, n=self.norms, a=self.acts, d=self.do)\n        \n        \n    def forward(self, x):\n        if self.bn == 0:\n            return self.ubb(x)\n        elif self.bn == 1:\n            return self.urb(x)\n        elif self.bn == 2:\n            x = self.rb(x)            \n            if self.inc == self.outc:\n                return x\n            return self.conv(x)\n        elif self.bn == 3:\n            return self.saspp(x)\n        elif self.bn == 4:\n            x = self.serb(x)\n            return self.conv1(x)\n        elif self.bn == 5:\n            return self.p3ab(x)\n        elif self.bn == 6:\n            x = self.rrcb(x)\n            if self.inc == self.outc:\n                return x\n            return self.conv(x)\n        elif self.bn == 7:\n            return self.urpub(x)\n        else:\n            raise \"Invalid Block number\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:21.592851Z","iopub.execute_input":"2025-03-30T15:20:21.593179Z","iopub.status.idle":"2025-03-30T15:20:21.604363Z","shell.execute_reply.started":"2025-03-30T15:20:21.593150Z","shell.execute_reply":"2025-03-30T15:20:21.603364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom torch import nn\n\nclass CS3DEANet(nn.Module):\n    def __init__(self, b, acts, norms, upsn, input_channels = 1, num_classes=2, initial_kernel=16):\n        super().__init__()\n        self.initial_kernel = initial_kernel\n        self.input_channels = input_channels\n        self.num_classes = num_classes\n        self.b = b\n        self.acts = acts\n        self.norms = norms\n        self.upsn = upsn\n        \n        self.r1 = Block(bn=self.b[0], inc=self.input_channels,   outc=self.initial_kernel,   kernel=3, norm=self.norms[0], act=self.acts[0], dr=None)\n        self.r2 = Block(bn=self.b[1], inc=self.initial_kernel*2, outc=self.initial_kernel*2, kernel=3, norm=self.norms[1], act=self.acts[1], dr=None)\n        self.r3 = Block(bn=self.b[2], inc=self.initial_kernel*4, outc=self.initial_kernel*4, kernel=3, norm=self.norms[2], act=self.acts[2], dr=None)\n        self.r4 = Block(bn=self.b[3], inc=self.initial_kernel*8, outc=self.initial_kernel*8, kernel=3, norm=self.norms[3], act=self.acts[3], dr=None)\n        self.r5 = Block(bn=self.b[4], inc=self.initial_kernel*4, outc=self.initial_kernel*4, kernel=3, norm=self.norms[4], act=self.acts[4], dr=None)\n        self.r6 = Block(bn=self.b[5], inc=self.initial_kernel*2, outc=self.initial_kernel*2, kernel=3, norm=self.norms[5], act=self.acts[5], dr=None)\n        self.r7 = Block(bn=self.b[6], inc=self.initial_kernel,   outc=self.num_classes,       kernel=3, norm=self.norms[6], act=self.acts[6], dr=None)\n        \n        self.m = MaxAvg(k=3)\n        self.u1 = Ups(s=3, i=self.initial_kernel*8, o=self.initial_kernel*4, k=3, n=self.norms[4], a=self.acts[4], d=None)\n        self.u2 = Ups(s=3, i=self.initial_kernel*4, o=self.initial_kernel*2, k=3, n=self.norms[5], a=self.acts[5], d=None)\n        self.u3 = Ups(s=3, i=self.initial_kernel*2, o=self.initial_kernel,   k=3, n=self.norms[6], a=self.acts[6], d=None)\n        \n        self.t1 = Transp(s=3, i=self.initial_kernel*8, o=self.initial_kernel*4, k=3, n=self.norms[4], a=self.acts[4], d=None)\n        self.t2 = Transp(s=3, i=self.initial_kernel*4, o=self.initial_kernel*2, k=3, n=self.norms[5], a=self.acts[5], d=None)\n        self.t3 = Transp(s=3, i=self.initial_kernel*2, o=self.initial_kernel,   k=3, n=self.norms[6], a=self.acts[6], d=None)\n        \n\n    def forward(self, x):\n        x1 = self.r1(x)\n        x = self.m(x1)\n        \n        x2 = self.r2(x)\n        x = self.m(x2)\n        \n        x3 = self.r3(x)\n        x = self.m(x3)\n        \n        x4 = self.r4(x)\n        if self.upsn[0] == 0:\n            xu1 = self.t1(x4)\n        elif self.upsn[0] == 1:\n            xu1 = self.u1(x4)\n        else:\n            raise \"Invalid upsampling \"\n        \n        xu1x3 = xu1+x3\n        x5 = self.r5(xu1x3)       \n        if self.upsn[1] == 0:\n            xu2 = self.t2(x5)\n        elif self.upsn[1] == 1:\n            xu2 = self.u2(x5)\n        else:\n            raise \"Invalid upsampling \"\n            \n        xu2x2 = xu2+x2\n        x6 = self.r6(xu2x2)         \n        if self.upsn[2] == 0:\n            xu3 = self.t3(x6)\n        elif self.upsn[2] == 1:\n            xu3 = self.u3(x6)\n        else:\n            raise \"Invalid upsampling \"\n        xu3x1 = xu3+x1\n        x7 = self.r7(xu3x1)  \n        \n        return x7\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:28.961507Z","iopub.execute_input":"2025-03-30T15:20:28.961836Z","iopub.status.idle":"2025-03-30T15:20:28.974984Z","shell.execute_reply.started":"2025-03-30T15:20:28.961807Z","shell.execute_reply":"2025-03-30T15:20:28.973972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from monai.losses import DiceLoss, DiceFocalLoss, FocalLoss, TverskyLoss, DiceCELoss\nfrom torch.optim import Adam, Adadelta, Adamax, SGD\n\nacts = ('memswish', 'relu', 'prelu', 'leakyrelu')\nnorms = ('BATCH', 'INSTANCE', ('GROUP', {'num_groups': 1}), '')\n\n\n\ndef loss_functions(l):\n    if l==0:\n        return DiceLoss(to_onehot_y=True, softmax=True)\n    elif l == 1:\n        return DiceFocalLoss(to_onehot_y=True, softmax=True)\n    elif l == 2:\n        return FocalLoss(to_onehot_y=True)\n    elif l == 3:\n        return TverskyLoss(to_onehot_y=True, softmax=True)\n    else:\n        print(\"Invalid loss function\")\n\n\ndef optimizers(o, params,lr=1e-4):\n    if o == 0:\n        return Adam(params, lr=lr)\n    elif o == 1:\n        return Adadelta(params, lr=lr)\n    elif o == 2:\n        return Adamax(params, lr=lr)\n    else:\n        return SGD(params, lr=lr, momentum=0.9)\n\n    \ndef todec(b):\n    return int(''.join(map(lambda x: str(int(x)), b)), 2)\n\n\ndef encoding(ch):\n    b, a, n, j = [], [], [], 0\n    \n    for i in range(7):  #0-21\n        b.append(todec(ch[j:j+3]))\n        j += 3        \n    for i in range(7):  #21-35\n        a.append(acts[todec(ch[j:j+2])])\n        j += 2        \n    for i in range(7):  #35-49\n        n.append(norms[todec(ch[j:j+2])])\n        j += 2        \n    upsn = ch[j:j+3]  #49-52\n    j += 3\n    ol = list(map(todec, (ch[j:j+2], ch[j+2:j+4])))  #52-56  optimizer-52,53  loss function-54,55\n    return b, a, n, upsn, ol[0], ol[1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:35.096511Z","iopub.execute_input":"2025-03-30T15:20:35.096832Z","iopub.status.idle":"2025-03-30T15:20:35.105607Z","shell.execute_reply.started":"2025-03-30T15:20:35.096809Z","shell.execute_reply":"2025-03-30T15:20:35.104697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data loading and Preprocessing","metadata":{}},{"cell_type":"raw","source":"Below code contains data loading and preprocessing of dataset","metadata":{}},{"cell_type":"code","source":"\"\"\" Select dataset name here \"\"\"\ntask_name =  \"Spleen\"  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:41.424807Z","iopub.execute_input":"2025-03-30T15:20:41.425099Z","iopub.status.idle":"2025-03-30T15:20:41.428882Z","shell.execute_reply.started":"2025-03-30T15:20:41.425075Z","shell.execute_reply":"2025-03-30T15:20:41.428067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/spleen/data/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:45.861819Z","iopub.execute_input":"2025-03-30T15:20:45.862113Z","iopub.status.idle":"2025-03-30T15:20:46.033788Z","shell.execute_reply.started":"2025-03-30T15:20:45.862089Z","shell.execute_reply":"2025-03-30T15:20:46.032791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"Setup dataset path\"\"\"\n\nroot_dir = \"/kaggle/working/\"\nprint(root_dir)\ndataset_name = task_name\nimg_size = 96\nimg_shape= (img_size, img_size, img_size)\n# data_dir = \"/kaggle/input/spleen/data/\"+ task_name\ndata_dir = os.path.join(\"/kaggle/input/spleen/data\", task_name)\n# data_dir = os.path.join(\"/kaggle/input/spleen/data\", task_name)\n\n# train_images = sorted(glob.glob(os.path.join(data_dir, \"train\", \"images\", \"*.nii\")))\n# train_labels = sorted(glob.glob(os.path.join(data_dir, \"train\", \"labels\", \"*.nii\")))\n\n\ntrain_images = sorted(glob.glob(os.path.join(data_dir, \"train\", \"images\", \"*.nii\")))\ntrain_labels = sorted(glob.glob(os.path.join(data_dir, \"train\", \"labels\", \"*.nii\")))\n\nval_images = sorted(glob.glob(os.path.join(data_dir, \"val\", \"images\", \"*.nii\")))\nval_label = sorted(glob.glob(os.path.join(data_dir, \"val\", \"labels\", \"*.nii\")))\n\ntest_images = sorted(glob.glob(os.path.join(data_dir, \"test\", \"images\", \"*.nii\")))\ntest_labels = sorted(glob.glob(os.path.join(data_dir, \"test\", \"labels\", \"*.nii\")))\n\n\ntrain_files = [{\"image\": image_name, \"label\": label_name}\n    for image_name, label_name in zip(train_images, train_labels)]\n\nval_files = [{\"image\": image_name, \"label\": label_name}\n    for image_name, label_name in zip(val_images, val_label)]\n\ntest_files = [{\"image\": image_name, \"label\": label_name}\n    for image_name, label_name in zip(test_images, test_labels)]\n\nprint(len(train_files), len(val_files), len(test_files))\n\n\n\n\"\"\"Set deterministic training for reproducibility\"\"\"\n\nset_determinism(seed=0)\nif dataset_name == \"Spleen\":\n    max_intens = 164\n    min_intens = -57\n    train_transforms = Compose(\n        [\n            LoadImaged(keys=[\"image\", \"label\"]),\n            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n            ScaleIntensityRanged(\n                keys=[\"image\"], a_min=min_intens, a_max=max_intens,\n                b_min=0.0, b_max=1.0, clip=True,\n            ),\n            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n            Spacingd(keys=[\"image\", \"label\"], pixdim=(\n                1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n            RandCropByPosNegLabeld(\n                keys=[\"image\", \"label\"],\n                label_key=\"label\",\n                spatial_size=img_shape,\n                pos=1,\n                neg=1,\n                num_samples=4,\n                image_key=\"image\",\n                image_threshold=0,\n            ),\n        ]\n    )\nelif dataset_name == \"Heart\":    \n    max_intens = 2033\n    min_intens = 0\n    train_transforms = Compose(\n        [\n            LoadImaged(keys=[\"image\", \"label\"]),\n            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n            ScaleIntensityRanged(\n                keys=[\"image\"], a_min=min_intens, a_max=max_intens,\n                b_min=0.0, b_max=1.0, clip=True,\n            ),\n            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n            Spacingd(keys=[\"image\", \"label\"], pixdim=(\n                1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n            RandAffined(\n                keys=['image', 'label'],\n                mode=('bilinear', 'nearest'),\n                prob=1.0, spatial_size=img_shape,\n                rotate_range=(0, 0, np.pi/15),\n                scale_range=(0.1, 0.1, 0.1)),\n        ]\n    )\n    \n    \nval_transforms = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n        ScaleIntensityRanged(\n            keys=[\"image\"], a_min=min_intens, a_max=max_intens,\n            b_min=0.0, b_max=1.0, clip=True,\n        ),\n        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n    ]\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nnow = 2\ncr = 1.0\ntrain_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=cr, num_workers=now)\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=now)\n\nval_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=cr, num_workers=now)\nval_loader = DataLoader(val_ds, batch_size=1, num_workers=now)\n\ntest_ds = CacheDataset(data=test_files, transform=val_transforms, cache_rate=cr, num_workers=now)\ntest_loader = DataLoader(test_ds, batch_size=1, num_workers=now)\n\ntest_org_transforms = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\"], pixdim=(\n            1.5, 1.5, 2.0), mode=\"bilinear\"),\n        ScaleIntensityRanged(\n            keys=[\"image\"], a_min=min_intens, a_max=max_intens,\n            b_min=0.0, b_max=1.0, clip=True,\n        ),\n        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n    ]\n)\n\ntest_org_ds = Dataset(\n    data=test_files, transform=test_org_transforms)\ntest_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=4)\n\npost_transforms = Compose([\n    Invertd(\n        keys=\"pred\",\n        transform=test_org_transforms,\n        orig_keys=\"image\",\n        meta_keys=\"pred_meta_dict\",\n        orig_meta_keys=\"image_meta_dict\",\n        meta_key_postfix=\"meta_dict\",\n        nearest_interp=False,\n        to_tensor=True,\n        device=\"cpu\",\n    ),\n    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n    AsDiscreted(keys=\"label\", to_onehot=2),\n])\n\nfile_name = '/kaggle/working/'+dataset_name+'.csv'\nprint(file_name)\n\nif not os.path.exists(file_name):\n    print(\"writing new\")\n    with open(file_name,'a') as fp:\n        wr = csv.writer(fp, dialect='excel')\n        wr.writerow(['Generation', 'Index', 'epoch', 'Val_Dice', 'Test_Dice',\\\n                     'Test_IOU', 'Ch', 'Params', 'Time', 'Start', 'End', 'Task'])\n        \ndef create_dir(path):\n    if not os.path.exists(path):\n        print(f\"{path} created\")\n        os.makedirs(path)\n        \n\ndef calc_ff(model):\n    input_tensor = torch.randn(1,1,img_size,img_size,img_size)\n\n    # Measure FLOPs and Parameters\n    input_flops = input_tensor.to(device)\n    macs, params = profile(model, inputs=(input_flops,))\n    print(f\"FLOPs: {macs / 1e9} Gmacs\")\n    print(f\"Parameters: {params / 1e6} M\")\n    return macs / 1e9, params / 1e6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:20:49.864028Z","iopub.execute_input":"2025-03-30T15:20:49.864384Z","iopub.status.idle":"2025-03-30T15:22:09.143132Z","shell.execute_reply.started":"2025-03-30T15:20:49.864349Z","shell.execute_reply":"2025-03-30T15:22:09.142370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"Below code displays the sample image with label","metadata":{}},{"cell_type":"code","source":"for batch_data in test_loader:\n    inputs, labels = (\n        batch_data[\"image\"].to(device),\n        batch_data[\"label\"].to(device),\n    )\n    break\nprint(inputs.shape, labels.shape)\n\nip = np.squeeze(inputs)\nop = np.squeeze(labels)\n\n# check_ds = Dataset(data=val_files, transform=val_transforms)\n# check_loader = DataLoader(check_ds, batch_size=1)\n# check_data = first(check_loader)\n# image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\nprint(f\"image shape: {ip.shape}, label shape: {op.shape}\")\n# plot the slice [:, :, 80]\nplt.figure(\"check\", (12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"image\")\nplt.imshow(ip[:, :, 80], cmap=\"gray\")\nplt.subplot(1, 2, 2)\nplt.title(\"label\")\nplt.imshow(op[:, :, 80])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:22:47.256079Z","iopub.execute_input":"2025-03-30T15:22:47.256459Z","iopub.status.idle":"2025-03-30T15:22:48.327134Z","shell.execute_reply.started":"2025-03-30T15:22:47.256427Z","shell.execute_reply":"2025-03-30T15:22:48.326184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fitness evaluation","metadata":{}},{"cell_type":"raw","source":"The below code contains the conversion of chameleon vector to 3D CNN model and fitness evaluation of a converted model","metadata":{}},{"cell_type":"code","source":"\"\"\" Execute a typical PyTorch training process\"\"\"\nmax_epochs = 150\nsw_batch_size = 1\ncreate_dir(root_dir)\n\ndef cal_params(model):\n    return sum(p.numel() for p in model.parameters())\n\ndef runModel(g, ind, ch, file_name='results_'+dataset_name+'.csv'):    \n    print(\"\\n\\n\",g,ind)\n    \n    ptcl = ' '.join(map(str, ch))\n    f = pandas.read_csv(file_name)\n    if ptcl in f['Ch'].values:\n        print(\"already found\")\n        f1s = float(np.max(f[f['Ch'] == ptcl]['Test_Dice']))\n        return f1s\n\n    b, a, n, upsn, o, l = encoding(ch)\n    print(b, a, n, upsn, o, l)\n    model = CS3DEANet(b, a, n, upsn, input_channels=1, num_classes=2, initial_kernel=16)\n    Total_params = cal_params(model)\n    \n    # model\n    model = model.to(device)\n    optimizer = optimizers(o, model.parameters(), lr = 0.00035)\n    loss_function = loss_functions(l)\n    \n    # Setup checkpoint paths\n    checkpoint_dir = os.path.join(root_dir, \"checkpoints\")\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{dataset_name}_{g}_{ind}.pth\")\n    best_model_path = os.path.join(root_dir, f\"best_metric_model_{dataset_name}_{g}_{ind}.pth\")\n    \n    # Initialize training state\n    start_epoch = 0\n    best_metric = -1\n    best_metric_epoch = -1\n    epoch_loss_values = []\n    metric_values = []\n    \n    # Try to load checkpoint if exists\n    if os.path.exists(checkpoint_path):\n        print(f\"Loading checkpoint from {checkpoint_path}\")\n        checkpoint = torch.load(checkpoint_path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_epoch = checkpoint['epoch']\n        best_metric = checkpoint['best_metric']\n        best_metric_epoch = checkpoint['best_metric_epoch']\n        epoch_loss_values = checkpoint['epoch_loss_values']\n        metric_values = checkpoint['metric_values']\n        print(f\"Resuming from epoch {start_epoch}\")\n    \n    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n    mean_iou = MeanIoU(include_background=False, reduction=\"mean\")\n\n    val_interval = 2\n    post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n    post_label = Compose([AsDiscrete(to_onehot=2)])\n    start = time.time()\n    \n    for epoch in range(start_epoch, max_epochs):\n        print(\"-\" * 10)\n        print(f\"epoch {epoch + 1}/{max_epochs}\")\n        model.train()\n        epoch_loss = 0\n        step = 0\n        for batch_data in train_loader:\n            step += 1\n            inputs, labels = (\n                batch_data[\"image\"].to(device),\n                batch_data[\"label\"].to(device),\n            )       \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = loss_function(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            print(\n                f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n                f\"train_loss: {loss.item():.4f}\")\n        epoch_loss /= step\n        epoch_loss_values.append(epoch_loss)\n        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n        if (epoch + 1) % val_interval == 0:\n            model.eval()\n            with torch.no_grad():\n                for val_data in val_loader:\n                    val_inputs, val_labels = (\n                        val_data[\"image\"].to(device),\n                        val_data[\"label\"].to(device),\n                    )\n                    roi_size = (160, 160, 160)\n\n                    val_outputs = sliding_window_inference(\n                        val_inputs, roi_size, sw_batch_size, model)\n                    val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n                    val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n                    dice_metric(y_pred=val_outputs, y=val_labels)\n\n                metric = dice_metric.aggregate().item()\n                dice_metric.reset()\n\n                metric_values.append(metric)\n                if metric > best_metric:\n                    best_metric = metric\n                    best_metric_epoch = epoch + 1\n                    torch.save(model.state_dict(), best_model_path)\n                    print(f\"saved new best metric model at {best_model_path}\")\n                print(\n                    f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n                    f\"\\nbest mean dice: {best_metric:.4f} \"\n                    f\"at epoch: {best_metric_epoch}\"\n                )\n        \n        # Save checkpoint every 10 epochs\n        if (epoch + 1) % 10 == 0:\n            checkpoint = {\n                'epoch': epoch + 1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_metric': best_metric,\n                'best_metric_epoch': best_metric_epoch,\n                'epoch_loss_values': epoch_loss_values,\n                'metric_values': metric_values,\n            }\n            torch.save(checkpoint, checkpoint_path)\n            print(f\"Saved checkpoint at epoch {epoch + 1}\")\n                \n        if epoch > 60 and best_metric < 0.15 and metric < 0.15:\n            print(\"Stopping training after 20th epoch as metric not increasing\")\n            break\n\n    print(\n        f\"train completed, best_metric: {best_metric:.4f} \"\n        f\"at epoch: {best_metric_epoch}\")\n\n    end = time.time()\n    \n    \"\"\"Evaluation on test dataset\"\"\"\n    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n    mean_iou = MeanIoU(include_background=False, reduction=\"mean\")\n\n    model.load_state_dict(torch.load(best_model_path))\n    model.eval()\n\n    with torch.no_grad():\n        for test_data in test_org_loader:\n            test_inputs = test_data[\"image\"].to(device)\n            roi_size = (160, 160, 160)\n            test_data[\"pred\"] = sliding_window_inference(\n                test_inputs, roi_size, sw_batch_size, model)\n            test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n            test_outputs, test_labels = from_engine([\"pred\", \"label\"])(test_data)\n            dice_metric(y_pred=test_outputs, y=test_labels)\n            mean_iou(y_pred=test_outputs, y=test_labels)\n\n        dice_metric_org = dice_metric.aggregate().item()\n        iou_metric_org = mean_iou.aggregate().item()\n        dice_metric.reset()\n        mean_iou.reset()\n\n    print(\"Dice Metric on Test dataset: \", dice_metric_org)\n    print(\"IOU Metric on Test dataset: \", iou_metric_org)\n\n    l=[]\n    l.extend([g, ind, best_metric_epoch, best_metric, dice_metric_org,\\\n              iou_metric_org, ptcl, Total_params, int((end-start)/60), \\\n              datetime.fromtimestamp(start).strftime('%Y-%m-%d %H:%M:%S'),\\\n              datetime.fromtimestamp(end).strftime('%Y-%m-%d %H:%M:%S'), dataset_name])\n    with open(file_name,'a') as fp:\n        wr = csv.writer(fp, dialect='excel')\n        wr.writerow(l)\n\n    return dice_metric_org","metadata":{"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:23:50.683439Z","iopub.execute_input":"2025-03-30T15:23:50.683788Z","iopub.status.idle":"2025-03-30T15:23:50.703334Z","shell.execute_reply.started":"2025-03-30T15:23:50.683759Z","shell.execute_reply":"2025-03-30T15:23:50.702258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CS3DEA-Net","metadata":{"tags":[]}},{"cell_type":"raw","source":"The CSA algorithm is implemented below to find optimal parameters for 3D CNN architecture and its hyperparameters from the designed search space.","metadata":{}},{"cell_type":"code","source":"\n# Main parameters of CSA\nsearchAgents = 20\ndim = 56\nub = [1] * dim\nlb = [0] * dim\nrho = 1.0\np1 = 2.0\np2 = 2.0\nc1 = 2.0\nc2 = 1.8\ngamma = 2.0\nalpha = 4.0\nbeta = 3.0\niteMax = 30\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom enum import Enum\nfrom math import atan, sqrt, tanh, erf, e, pi\nfrom copy import copy\n\ndef initialization(Particles_no, dim):\n    C = np.random.randint(0,2,(Particles_no, dim))               \n    return C\n\n\n# transfer functions V-Shape and S-Shape\nclass TransferFuncion(Enum):\n    \"\"\"enumeration value of transfer function\n    \"\"\"\n    V1 = 1\n    V2 = 2\n    V3 = 3\n    V4 = 4\n    S1 = 5\n    S2 = 6\n    S3 = 7\n    S4 = 8\n    \n    \ndef transfer_function(transfer_function_type: TransferFuncion, a: float) -> float:\n    \"\"\"8 transfer functions (4 V-Shapes and 4 S-Shapes) that map values to the [0, 1] interval\n\n     Args:\n         transfer_function_type (TransferFuncion): transfer function type\n         a (float): any real value\n\n     Returns:\n         float: the value mapped to the interval [0, 1] after the transfer function\n     \"\"\"\n    if transfer_function_type == TransferFuncion.V1:\n        return abs((2/pi)*atan((pi/2)*a))\n    \n    elif transfer_function_type == TransferFuncion.V2:\n        return abs(tanh(a))\n        \n    elif transfer_function_type == TransferFuncion.V3:\n        return abs(a/(sqrt(1+a**2)))\n    \n    elif transfer_function_type == TransferFuncion.V4:\n        return abs(erf((sqrt(pi)/2)*a))\n    \n    elif transfer_function_type == TransferFuncion.S1:\n        return 1/(1+e**(-a))\n    \n    elif transfer_function_type == TransferFuncion.S2:\n        return 1/(1+e**(-2*a))\n    \n    elif transfer_function_type == TransferFuncion.S3:\n        return 1/(1+(e**(-a/2)))\n    \n    elif transfer_function_type == TransferFuncion.S4:\n        return 1/(1+(e**(-a/3)))\n    \n    else:\n        print('[ERROR] Unknow transfer function type, Please use V1~V4 or S1~S4')\n        exit\n        \n        \ndef arr2bin(arr, tf):\n    for i in range(arr.shape[0]):\n        if transfer_function(tf, arr[i]) >= np.random.rand():\n            arr[i] = 0\n        else:\n            arr[i] = 1\n    return arr\n\n\ndef  fobj(g, ind, particle):\n    particle = list(map(int, particle)) \n    # try:\n    fitness_score = runModel(g, ind, particle, file_name)\n    # except Exception as e:\n    #     print(e)\n    #     fitness_score = 0\n    print(fitness_score)\n    return fitness_score\n\n\ntf=TransferFuncion.V2\nchameleonPositions = initialization(searchAgents,dim)\nfit = np.zeros((searchAgents,1))\n\nfor i in range(searchAgents):\n    fit[i] = fobj(0, i, chameleonPositions[i])\n\n    \n\nprint(fit, chameleonPositions)\n\n## Convergence curve\ncg_curve = np.zeros(iteMax)\n\n## Initalize the parameters of CSA\nfitness = fit.copy()\n# print(fit)\nfmin0,index = np.amax(fit), np.argmax(fit)\nchameleonBestPosition = chameleonPositions.copy()\ncg_curve[0] = fmin0\n\n# chameleonPositions, fit\ngPosition = chameleonPositions[index]\nv = 0.1 * chameleonBestPosition\nv0 = 0.0 * v\n\nprint(fmin0,index)\n\n\n\n# CSA loop starts from here\nfor t in range(1,iteMax):\n    a = 0.5 #2590 * (1 - np.exp(- np.log(t)))\n    omega = (1 - (t / iteMax)) ** (rho * np.sqrt(t / iteMax))\n    p1 = 2 * np.exp(- 2 * (t / iteMax) ** 2)\n    p2 = 2 / (1 + np.exp((- t + iteMax / 2) / 100))\n    mu = gamma * np.exp(- (alpha * t / iteMax) ** beta)\n    ch = np.ceil(searchAgents * np.random.rand(searchAgents)-1)\n    \n    ## Update the position of CSA (Exploration)\n    for i in range(searchAgents):\n        if np.random.rand() >= 0.1:\n            chameleonPositions[i] = chameleonPositions[i] + p1 * (chameleonBestPosition[int(ch[i])] - chameleonPositions[i]) * np.random.rand() + p2 * (gPosition - chameleonPositions[i]) * np.random.rand()\n        else:\n            for j in range(dim):\n                chameleonPositions[i][j] = gPosition[j] + mu * ((ub[j] - lb[j]) * np.random.rand() + lb[j]) * np.sign(np.random.rand() - 0.5)\n\n    for i in range(searchAgents):\n        v[i] = omega * v[i] + p1 * (chameleonBestPosition[i] - chameleonPositions[i]) * np.random.rand() + p2 * (gPosition - chameleonPositions[i]) * np.random.rand()\n        chameleonPositions[i] = chameleonPositions[i] + (v[i] ** 2 - v0[i] ** 2) / (2 * a)\n    v0 = v\n    \n    for i in range(searchAgents):\n        chameleonPositions[i] = arr2bin(arr=chameleonPositions[i], tf=tf)    \n        fit[i] = fobj(t, i, chameleonPositions[i])\n        print(fit[i], fitness[i])\n        if fit[i] > fitness[i]:\n            print(\"updated\")\n            chameleonBestPosition[i] = chameleonPositions[i]\n            fitness[i] = fit[i]\n            \n    ## Evaluate the new positions\n    fmin,index = np.amax(fitness), np.argmax(fitness)\n    # Updating gPosition and best fitness\n    if fmin > fmin0:\n        gPosition = chameleonBestPosition[index]\n        fmin0 = fmin\n    cg_curve[t] = fmin0\n    \n    print(\"\\n\\nAt iteration  \", t)\n    print(chameleonBestPosition, fitness)","metadata":{"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T13:10:59.137061Z","iopub.execute_input":"2025-03-30T13:10:59.137323Z","execution_failed":"2025-03-30T15:00:14.111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Top discovered models","metadata":{}},{"cell_type":"code","source":"if dataset_name == \"Spleen\":\n    best_ch = [0 ,0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n    save_path = \"/kaggle/working/best_metric_model_Spleen_1_15.pth\"\nelif dataset_name == \"Heart\":\n    best_ch = [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n    save_path = \"CS3DEA_Net_best_Heart.pth\" \nprint(dataset_name)\n\n\nb, a, n, upsn, o, l = encoding(best_ch)\ncs3dea = CS3DEANet(b, a, n, upsn, input_channels=1, num_classes=2, initial_kernel=16)\ncs3dea = cs3dea.to(device)\ncs3dea.load_state_dict(torch.load(save_path))\n# cs3dea.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n# cs3dea.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n\n\ncs3dea.eval()\n\ncalc_ff(cs3dea)\nsummary(cs3dea, (1,img_size,img_size,img_size))\n# optimizer = optimizers(o, cs3dea.parameters(), lr = 0.00035)\n# loss_function = loss_functions(l)\n# runModel(\"CS3DEA_Net\", cs3dea, optimizer, loss_function)","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:24:29.761720Z","iopub.execute_input":"2025-03-30T15:24:29.762024Z","iopub.status.idle":"2025-03-30T15:24:31.113437Z","shell.execute_reply.started":"2025-03-30T15:24:29.762001Z","shell.execute_reply":"2025-03-30T15:24:31.112497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation on test dataset","metadata":{}},{"cell_type":"code","source":"\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\")\nmean_iou = MeanIoU(include_background=False, reduction=\"mean\")\n\n# cs3dea.load_state_dict(torch.load(save_path))\n# cs3dea.eval()\n\nwith torch.no_grad():\n    for test_data in test_org_loader:\n        test_inputs = test_data[\"image\"].to(device)\n        roi_size = (160, 160, 160)\n        test_data[\"pred\"] = sliding_window_inference(\n            test_inputs, roi_size, sw_batch_size, cs3dea)\n        test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n        test_outputs, test_labels = from_engine([\"pred\", \"label\"])(test_data)\n        dice_metric(y_pred=test_outputs, y=test_labels)\n        mean_iou(y_pred=test_outputs, y=test_labels)\n\n    # aggregate the final mean dice result\n    dice_metric_org = dice_metric.aggregate().item()\n    iou_metric_org = mean_iou.aggregate().item()\n    # reset the status for next validation round\n    dice_metric.reset()\n    mean_iou.reset()\n\nprint(\"Dice Metric on Test dataset: \", dice_metric_org)\nprint(\"IOU Metric on Test dataset: \", iou_metric_org)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:24:45.488969Z","iopub.execute_input":"2025-03-30T15:24:45.489274Z","iopub.status.idle":"2025-03-30T15:25:38.662989Z","shell.execute_reply.started":"2025-03-30T15:24:45.489250Z","shell.execute_reply":"2025-03-30T15:25:38.661108Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test image results","metadata":{}},{"cell_type":"code","source":"\nwith torch.no_grad():\n    for i, test_data in enumerate(test_loader):\n        roi_size = (160, 160, 160)\n        sw_batch_size = 4\n        test_outputs = sliding_window_inference(\n            test_data[\"image\"].to(device), roi_size, sw_batch_size, cs3dea\n        )\n        # plot the slice [:, :, 80]\n        plt.figure(\"check\", (18, 6))\n        plt.subplot(1, 3, 1)\n        plt.title(f\"image {i}\")\n        plt.imshow(test_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n        plt.subplot(1, 3, 2)\n        plt.title(f\"label {i}\")\n        plt.imshow(test_data[\"label\"][0, 0, :, :, 80])\n        plt.subplot(1, 3, 3)\n        plt.title(f\"output {i}\")\n        plt.imshow(torch.argmax(\n            test_outputs, dim=1).detach().cpu()[0, :, :, 80])\n        plt.show()","metadata":{"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:27:06.869796Z","iopub.execute_input":"2025-03-30T15:27:06.870129Z","iopub.status.idle":"2025-03-30T15:27:16.458138Z","shell.execute_reply.started":"2025-03-30T15:27:06.870100Z","shell.execute_reply":"2025-03-30T15:27:16.457133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## saving results\nmodel_name=\"CS3DEA_Net\"\nres_save_path = '/kaggle/working/'+dataset_name+'_top_model'\ncreate_dir(res_save_path)\n\nwith torch.no_grad():\n    for i, test_data in enumerate(test_loader):\n        roi_size = (160, 160, 160)\n        sw_batch_size = 4\n        test_outputs = sliding_window_inference(\n            test_data[\"image\"].to(device), roi_size, sw_batch_size, cs3dea\n        )\n        plt.imsave(res_save_path+\"/\"+str(i)+\"_image.png\", test_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n        plt.imsave(res_save_path+\"/\"+str(i)+\"_label.png\", test_data[\"label\"][0, 0, :, :, 80], cmap=\"gray\")\n        plt.imsave(res_save_path+\"/\"+str(i)+\"_output.png\", \n                   torch.argmax(test_outputs, dim=1).detach().cpu()[0, :, :, 80], cmap=\"gray\")\n        print(f\"{i} saved in res_save_path\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:27:21.526144Z","iopub.execute_input":"2025-03-30T15:27:21.526503Z","iopub.status.idle":"2025-03-30T15:27:28.279133Z","shell.execute_reply.started":"2025-03-30T15:27:21.526468Z","shell.execute_reply":"2025-03-30T15:27:28.278267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nimport glob\nimport random\nimport numpy as np\nimport torch\nfrom torch.optim import Adam\nfrom torch.amp import GradScaler, autocast\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom monai.data import CacheDataset, Dataset, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    LoadImaged,\n    EnsureChannelFirstd,\n    Spacingd,\n    ScaleIntensityd,\n    CropForegroundd,\n    CenterSpatialCropd,\n    RandFlipd,\n    RandRotate90d,\n    RandZoomd,\n    RandAdjustContrastd,\n    Rand3DElasticd,\n    RandAffined,\n    ToTensord,\n)\nfrom monai.networks.nets import UNet\nfrom monai.losses import DiceCELoss\nfrom monai.metrics import DiceMetric\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T08:29:33.942098Z","iopub.execute_input":"2025-04-28T08:29:33.942463Z","iopub.status.idle":"2025-04-28T08:29:33.948331Z","shell.execute_reply.started":"2025-04-28T08:29:33.942434Z","shell.execute_reply":"2025-04-28T08:29:33.947504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_root = \"/kaggle/input/spleen/data/Spleen\"\ncheckpoint_dir = \"./checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmax_epochs = 100\ntrain_batch_size = 2\nval_batch_size = 1\nlearning_rate = 1e-4\npatience = 10\nroi_size = (96, 96, 96)\n\n# ----------------------------\n# Build dataset paths\n# ----------------------------\ndef make_dataset(phase):\n    img_dir = os.path.join(data_root, phase, \"images\")\n    lbl_dir = os.path.join(data_root, phase, \"label\")\n    img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.nii*\")))\n    lbl_paths = sorted(glob.glob(os.path.join(lbl_dir, \"*.nii*\")))\n    assert img_paths and lbl_paths, f\"No files for {phase}\"\n    return [{\"image\": i, \"label\": l} for i, l in zip(img_paths, lbl_paths)]\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_files = make_dataset(\"train\")\nval_files = make_dataset(\"val\")\ntest_files = make_dataset(\"test\")\n\n# ----------------------------\n# Transforms\n# ----------------------------\ntrain_transforms = [\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityd(keys=[\"image\"]),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=roi_size),\n    RandFlipd(keys=[\"image\", \"label\"], spatial_axis=0, prob=0.5),\n    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, max_k=3),\n    RandZoomd(keys=[\"image\", \"label\"], prob=0.3, min_zoom=0.8, max_zoom=1.2),\n    RandAdjustContrastd(keys=[\"image\"], prob=0.3, gamma=(0.7,1.5)),\n    ToTensord(keys=[\"image\", \"label\"]),\n]\n\nval_transforms = [\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityd(keys=[\"image\"]),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=roi_size),\n    ToTensord(keys=[\"image\", \"label\"]),\n]\n\n# ----------------------------\n# Loaders\n# ----------------------------\ntrain_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\nval_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0)\ntrain_loader = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=2)\n\n# ----------------------------\n# Model setup\n# ----------------------------\nmodel = UNet(spatial_dims=3, in_channels=1, out_channels=2,\n             channels=(32,64,128,256,512), strides=(2,2,2,2), num_res_units=2, norm='batch').to(device)\nloss_function = DiceLoss(to_onehot_y=True, softmax=True)\noptimizer = Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5)\nscaler = GradScaler()\ndice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n\n# ----------------------------\n# Training & Validation\n# ----------------------------\nbest_metric = 0.0\nno_improve = 0\n\nfor epoch in range(1, max_epochs+1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        imgs, segs = batch['image'].to(device), batch['label'].to(device)\n        optimizer.zero_grad()\n        with autocast(device_type='cuda'):\n            outputs = model(imgs)\n            loss = loss_function(outputs, segs)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        epoch_loss += loss.item()\n    epoch_loss /= len(train_loader)\n    print(f\"Epoch {epoch}, Avg Loss: {epoch_loss:.4f}\")\n\n    # Validation phase\n    model.eval()\n    dice_metric.reset()\n    with torch.no_grad():\n        for val_batch in val_loader:\n            val_imgs, val_segs = val_batch['image'].to(device), val_batch['label'].to(device)\n            val_preds = sliding_window_inference(val_imgs, roi_size, 4, model)\n            dice_metric(y_pred=val_preds, y=val_segs)\n    mean_dice = dice_metric.aggregate().item()\n    print(f\"Validation Dice: {mean_dice:.4f}\")\n    scheduler.step(mean_dice)\n\n    if mean_dice > best_metric:\n        best_metric = mean_dice\n        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"best_model_epoch{epoch}_dice{best_metric:.4f}.pth\"))\n        no_improve = 0\n        print(\"Saved best model\")\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\"Early stopping\")\n            break\n\nprint(f\"Training finished. Best Dice = {best_metric:.4f}\")\n\n# ----------------------------\n# Test Phase\n# ----------------------------\nmodel.load_state_dict(torch.load(os.path.join(checkpoint_dir, f\"best_model_epoch{epoch-no_improve}_dice{best_metric:.4f}.pth\")))\nmodel.eval()\ntest_ds = Dataset(data=test_files, transform=val_transforms)\ntest_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n\ndice_metric.reset()\nwith torch.no_grad():\n    for test_batch in test_loader:\n        test_imgs, test_segs = test_batch['image'].to(device), test_batch['label'].to(device)\n        test_preds = sliding_window_inference(test_imgs, roi_size, 4, model)\n        dice_metric(y_pred=test_preds, y=test_segs)\n\nfinal_test_dice = dice_metric.aggregate().item()\nprint(f\"Test Mean Dice: {final_test_dice:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T08:24:31.993914Z","iopub.execute_input":"2025-04-28T08:24:31.994286Z","iopub.status.idle":"2025-04-28T08:27:08.733570Z","shell.execute_reply.started":"2025-04-28T08:24:31.994253Z","shell.execute_reply":"2025-04-28T08:27:08.732669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nimport glob\nimport random\nimport numpy as np\nimport torch\nfrom torch.optim import Adam\nfrom torch.amp import GradScaler, autocast\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom monai.data import CacheDataset, Dataset, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    LoadImaged,\n    EnsureChannelFirstd,\n    Spacingd,\n    ScaleIntensityd,\n    CropForegroundd,\n    SpatialPadd,\n    CenterSpatialCropd,\n    RandFlipd,\n    RandRotate90d,\n    RandZoomd,\n    RandAdjustContrastd,\n    Rand3DElasticd,\n    RandAffined,\n    ToTensord,\n)\nfrom monai.networks.nets import UNet\nfrom monai.losses import DiceCELoss\nfrom monai.metrics import DiceMetric\n\ndata_root = \"/kaggle/input/spleen/data/Spleen\"\ncheckpoint_dir = \"/kaggle/working/checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmax_epochs = 300\ntrain_batch_size = 2\nval_batch_size = 1\nlearning_rate = 5e-5\npatience = 20\nroi_size = (128, 128, 128)\n\n# ----------------------------\n# Build dataset paths\n# ----------------------------\ndef make_dataset(phase):\n    img_dir = os.path.join(data_root, phase, \"images\")\n    lbl_dir = os.path.join(data_root, phase, \"labels\")\n    img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.nii*\")))\n    lbl_paths = sorted(glob.glob(os.path.join(lbl_dir, \"*.nii*\")))\n    assert img_paths and lbl_paths, f\"No files for {phase}\"\n    return [{\"image\": i, \"label\": l} for i, l in zip(img_paths, lbl_paths)]\n\ntrain_files = make_dataset(\"train\")\nval_files = make_dataset(\"val\")\ntest_files = make_dataset(\"test\")\n\n# ----------------------------\n# Transforms\n# ----------------------------\ntrain_transforms = [\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityd(keys=[\"image\"]),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(128,128,128)),\n    CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=(128,128,128)),\n    RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0,1,2], prob=0.5),\n    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, max_k=3),\n    RandZoomd(keys=[\"image\", \"label\"], prob=0.3, min_zoom=0.8, max_zoom=1.2),\n    RandAdjustContrastd(keys=[\"image\"], prob=0.3, gamma=(0.7,1.5)),\n    Rand3DElasticd(keys=[\"image\", \"label\"], sigma_range=(5,8), magnitude_range=(100,200), prob=0.3),\n    RandAffined(keys=[\"image\", \"label\"], rotate_range=(0.1,0.1,0.1), prob=0.5),\n    ToTensord(keys=[\"image\", \"label\"]),\n]\n\nval_transforms = [\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityd(keys=[\"image\"]),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(128,128,128)),\n    CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=(128,128,128)),\n    ToTensord(keys=[\"image\", \"label\"]),\n]\n\n\n# ----------------------------\n# Loaders\n# ----------------------------\ntrain_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\nval_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0)\ntrain_loader = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=2)\n\n# ----------------------------\n# Model setup\n# ----------------------------\nmodel = UNet(spatial_dims=3, in_channels=1, out_channels=2,\n             channels=(32,64,128,256,512,1024), strides=(2,2,2,2,2), num_res_units=2, norm='batch').to(device)\nloss_function = DiceCELoss(to_onehot_y=True, softmax=True)\noptimizer = Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.5)\nscaler = GradScaler()\ndice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n\n# ----------------------------\n# Training & Validation\n# ----------------------------\nbest_metric = 0.0\nno_improve = 0\n\nfor epoch in range(1, max_epochs+1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        imgs, segs = batch['image'].to(device), batch['label'].to(device)\n        optimizer.zero_grad()\n        with autocast(device_type='cuda'):\n            outputs = model(imgs)\n            loss = loss_function(outputs, segs)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        epoch_loss += loss.item()\n    epoch_loss /= len(train_loader)\n    print(f\"Epoch {epoch}, Avg Loss: {epoch_loss:.4f}\")\n\n    model.eval()\n    dice_metric.reset()\n    with torch.no_grad():\n        for val_batch in val_loader:\n            val_imgs, val_segs = val_batch['image'].to(device), val_batch['label'].to(device)\n            val_preds = sliding_window_inference(val_imgs, roi_size, 4, model)\n            dice_metric(y_pred=val_preds, y=val_segs)\n    mean_dice = dice_metric.aggregate().item()\n    print(f\"Validation Dice: {mean_dice:.4f}\")\n    scheduler.step(mean_dice)\n\n    if mean_dice > best_metric:\n        best_metric = mean_dice\n        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"best_model_epoch{epoch}_dice{best_metric:.4f}.pth\"))\n        no_improve = 0\n        print(\"Saved best model\")\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\"Early stopping\")\n            break\n\nprint(f\"Training finished. Best Dice = {best_metric:.4f}\")\n\n# ----------------------------\n# Test Phase\n# ----------------------------\nmodel.load_state_dict(torch.load(os.path.join(checkpoint_dir, f\"best_model_epoch{epoch-no_improve}_dice{best_metric:.4f}.pth\")))\nmodel.eval()\ntest_ds = Dataset(data=test_files, transform=val_transforms)\ntest_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n\ndice_metric.reset()\nwith torch.no_grad():\n    for test_batch in test_loader:\n        test_imgs, test_segs = test_batch['image'].to(device), test_batch['label'].to(device)\n        test_preds = sliding_window_inference(test_imgs, roi_size, 4, model)\n        dice_metric(y_pred=test_preds, y=test_segs)\n\nfinal_test_dice = dice_metric.aggregate().item()\nprint(f\"Test Mean Dice: {final_test_dice:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T08:37:08.663504Z","iopub.execute_input":"2025-04-28T08:37:08.663953Z","iopub.status.idle":"2025-04-28T08:48:00.354880Z","shell.execute_reply.started":"2025-04-28T08:37:08.663909Z","shell.execute_reply":"2025-04-28T08:48:00.353811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.cuda.amp import autocast, GradScaler\nimport matplotlib.pyplot as plt\n\n# --- MONAI Imports ---\nfrom monai.data import CacheDataset, Dataset, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd,\n    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld,\n    RandFlipd, RandRotate90d, RandShiftIntensityd,\n    EnsureTyped, Compose\n)\nfrom monai.networks.nets import UNet\nfrom monai.networks.layers import Norm\nfrom monai.losses import DiceCELoss\nfrom monai.metrics import DiceMetric\nfrom monai.config import print_config\nfrom monai.utils import set_determinism\n\n# --- Configuration ---\nbase_data_dir = \"/kaggle/input/spleen\"\ndata_root = os.path.join(base_data_dir, \"data\", \"Spleen\")\ncheckpoint_dir = \"/kaggle/working/checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n# reproducibility\nseed = 42\nset_determinism(seed=seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint_config()\n\n# hyperparameters\nmax_epochs = 100\ntrain_batch_size = 2\nval_batch_size = 1\ntest_batch_size = 1\nlearning_rate = 5e-5\npatience = 20\ntrain_roi_size = (96, 96, 96)\ninfer_roi_size = (160, 160, 160)\nnum_samples_per_volume = 4\nsave_interval = 15  # epochs between periodic checkpoints\n\n# --- Dataset Listing ---\ndef make_dataset(phase):\n    phase_dir = os.path.join(data_root, phase)\n    img_paths = sorted(glob.glob(os.path.join(phase_dir, \"images\", \"*.nii*\")))\n    lbl_paths = sorted(glob.glob(os.path.join(phase_dir, \"labels\", \"*.nii*\")))\n    if not img_paths or not lbl_paths or len(img_paths) != len(lbl_paths):\n        raise RuntimeError(f\"Data error in phase '{phase}'.\")\n    return [{\"image\": i, \"label\": l} for i, l in zip(img_paths, lbl_paths)]\n\ntrain_files = make_dataset(\"train\")\nval_files = make_dataset(\"val\")\ntest_files = make_dataset(\"test\")\nprint(f\"Train/Val/Test: {len(train_files)}/{len(val_files)}/{len(test_files)}\")\n\n# --- Transforms ---\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\",\"label\"]), EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57,a_max=164,b_min=0.0,b_max=1.0,clip=True),\n    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),\n    RandCropByPosNegLabeld(keys=[\"image\",\"label\"], label_key=\"label\",\n                             spatial_size=train_roi_size, pos=1, neg=1, num_samples=num_samples_per_volume),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[0], prob=0.1),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[1], prob=0.1),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[2], prob=0.1),\n    RandRotate90d(keys=[\"image\",\"label\"], prob=0.1, max_k=3),\n    RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n    EnsureTyped(keys=[\"image\",\"label\"], track_meta=False),\n])\nval_transforms = Compose([\n    LoadImaged(keys=[\"image\",\"label\"]), EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57,a_max=164,b_min=0.0,b_max=1.0,clip=True),\n    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),\n    EnsureTyped(keys=[\"image\",\"label\"], track_meta=True),\n])\n\n# --- DataLoaders ---\ntrain_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\nval_ds   = CacheDataset(data=val_files,   transform=val_transforms,   cache_rate=1.0, num_workers=4)\ntest_ds  = Dataset(data=test_files,      transform=val_transforms)\n\ntrain_loader = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True,  num_workers=4, pin_memory=torch.cuda.is_available())\nval_loader   = DataLoader(val_ds,   batch_size=val_batch_size,   shuffle=False, num_workers=4, pin_memory=torch.cuda.is_available())\ntest_loader  = DataLoader(test_ds,  batch_size=test_batch_size,  shuffle=False, num_workers=4, pin_memory=torch.cuda.is_available())\n\n# --- Model & Optimizer ---\nmodel = UNet(spatial_dims=3, in_channels=1, out_channels=2,\n             channels=(32,64,128,256,512), strides=(2,2,2,2), num_res_units=2, norm=Norm.BATCH).to(device)\nloss_fn   = DiceCELoss(to_onehot_y=True, softmax=True)\noptimizer = Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.5, verbose=True)\nscaler    = GradScaler()\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n\n# --- Training & Validation ---\nbest_metric, best_epoch, epochs_no_improve = -1.0, -1, 0\nfor epoch in range(1, max_epochs+1):\n    # Training\n    model.train(); train_loss = 0.0\n    for i, batch in enumerate(train_loader, 1):\n        imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n        optimizer.zero_grad()\n        with autocast(enabled=torch.cuda.is_available()):\n            preds = model(imgs)\n            loss = loss_fn(preds, lbls)\n        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n        train_loss += loss.item()\n    print(f\"Epoch {epoch}/{max_epochs} - Train loss: {train_loss/i:.4f}\")\n\n    # Validation\n    model.eval(); dice_metric.reset()\n    with torch.no_grad():\n        for batch in val_loader:\n            imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n            outputs = sliding_window_inference(\n                imgs, roi_size=infer_roi_size, sw_batch_size=4,\n                predictor=model, overlap=0.5, mode=\"gaussian\"\n            )\n            probs = torch.softmax(outputs, dim=1)\n            seg = torch.argmax(probs, dim=1)\n            onehot_pred = F.one_hot(seg, num_classes=2).permute(0,4,1,2,3).float()\n            gt = lbls.squeeze(1).long()\n            onehot_gt = F.one_hot(gt, num_classes=2).permute(0,4,1,2,3).float()\n            for b in range(onehot_pred.shape[0]):\n                dice_metric(y_pred=[onehot_pred[b]], y=[onehot_gt[b]])\n    val_dice = dice_metric.aggregate().item()\n    print(f\"  Val Dice: {val_dice:.4f}\")\n    scheduler.step(val_dice)\n\n    # Save best model\n    if val_dice > best_metric:\n        best_metric, best_epoch, epochs_no_improve = val_dice, epoch, 0\n        if 'best_ckpt' in globals() and os.path.exists(best_ckpt): os.remove(best_ckpt)\n        best_ckpt = os.path.join(checkpoint_dir, f\"best_ep{epoch}_dice{val_dice:.4f}.pth\")\n        torch.save(model.state_dict(), best_ckpt)\n        print(f\"  Saved best model: {best_ckpt}\")\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(\"Early stopping\")\n            break\n\n    # Periodic checkpoint\n    if epoch % save_interval == 0:\n        periodic_ckpt = os.path.join(checkpoint_dir, f\"ckpt_epoch{epoch}.pth\")\n        torch.save(model.state_dict(), periodic_ckpt)\n        print(f\"  Saved periodic checkpoint: {periodic_ckpt}\")\n\nprint(f\"Training complete. Best val dice: {best_metric:.4f} at epoch {best_epoch}\")\n\n# --- Test Phase ---\nprint(\"\\n--- Test Evaluation ---\")\nif not os.path.exists(best_ckpt): raise FileNotFoundError(\"Checkpoint not found.\")\nmodel.load_state_dict(torch.load(best_ckpt, map_location=device))\nmodel.eval(); dice_metric.reset()\nwith torch.no_grad():\n    for batch in test_loader:\n        imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n        outputs = sliding_window_inference(\n            imgs, roi_size=infer_roi_size, sw_batch_size=4,\n            predictor=model, overlap=0.5, mode=\"gaussian\"\n        )\n        probs = torch.softmax(outputs, dim=1)\n        seg = torch.argmax(probs, dim=1)\n        onehot_pred = F.one_hot(seg, num_classes=2).permute(0,4,1,2,3).float()\n        gt = lbls.squeeze(1).long()\n        onehot_gt = F.one_hot(gt, num_classes=2).permute(0,4,1,2,3).float()\n        for b in range(onehot_pred.shape[0]):\n            dice_metric(y_pred=[onehot_pred[b]], y=[onehot_gt[b]])\nfinal_test_dice = dice_metric.aggregate().item()\nprint(f\"Test Mean Dice: {final_test_dice:.4f}\")\n\n# --- Plot Examples ---\nprint(\"\\n--- Plotting Examples ---\")\nplots = 0\nfor batch in val_loader:\n    if plots >= 3: break\n    img_np = batch['image'][0,0].cpu().numpy()\n    lbl_np = batch['label'][0,0].cpu().numpy()\n    with torch.no_grad():\n        out = sliding_window_inference(\n            batch['image'].to(device), roi_size=infer_roi_size, sw_batch_size=4,\n            predictor=model, overlap=0.5, mode=\"gaussian\"\n        )\n        pred_np = torch.argmax(torch.softmax(out, dim=1), dim=1)[0].cpu().numpy()\n    sl = img_np.shape[2]//2\n    plt.figure(figsize=(12,4))\n    plt.subplot(1,3,1); plt.imshow(img_np[:,:,sl], cmap=\"gray\"); plt.axis('off'); plt.title(f\"Img {plots}\")\n    plt.subplot(1,3,2); plt.imshow(lbl_np[:,:,sl]); plt.axis('off'); plt.title(f\"Lbl {plots}\")\n    plt.subplot(1,3,3); plt.imshow(pred_np[:,:,sl]); plt.axis('off'); plt.title(f\"Pred {plots}\")\n    plt.tight_layout(); plt.show()\n    plots += 1\n\nprint(\"Done.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T09:55:30.230323Z","iopub.execute_input":"2025-04-28T09:55:30.230733Z","iopub.status.idle":"2025-04-28T11:43:12.998916Z","shell.execute_reply.started":"2025-04-28T09:55:30.230692Z","shell.execute_reply":"2025-04-28T11:43:12.997911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.cuda.amp import autocast, GradScaler\nimport matplotlib.pyplot as plt\n\n# MONAI imports\nfrom monai.data import CacheDataset, Dataset, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd,\n    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld,\n    RandFlipd, RandRotate90d, RandShiftIntensityd,\n    EnsureTyped, Compose\n)\nfrom monai.losses import DiceCELoss\nfrom monai.metrics import DiceMetric\nfrom monai.config import print_config\nfrom monai.utils import set_determinism\n\n# Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint_config()\nprint(f\"Using device: {device}\")\n\n# Reproducibility\nseed = 42\nset_determinism(seed=seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Hyperparameters\nmax_epochs = 300\ntrain_batch_size = 1\nval_batch_size = 1\ntest_batch_size = 1\nlearning_rate = 5e-5\npatience = 20\ntrain_roi_size = (64, 64, 64)\ninfer_roi_size = (128, 128, 128)\nsave_interval = 15\n\n# Paths\nbase_data_dir = \"/kaggle/input/spleen\"\ndata_root = os.path.join(base_data_dir, \"data\", \"Spleen\")\ncheckpoint_dir = \"/kaggle/working/checkpoints_unet++\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n# Dataset\ndef make_dataset(phase):\n    img_dir = os.path.join(data_root, phase, \"images\")\n    lbl_dir = os.path.join(data_root, phase, \"labels\")\n    imgs = sorted(glob.glob(os.path.join(img_dir, \"*.nii*\")))\n    lbls = sorted(glob.glob(os.path.join(lbl_dir, \"*.nii*\")))\n    assert len(imgs) == len(lbls) and len(imgs) > 0, f\"Data error in {phase}\"\n    return [{\"image\": i, \"label\": l} for i, l in zip(imgs, lbls)]\n\ntrain_files = make_dataset(\"train\")\nval_files = make_dataset(\"val\")\ntest_files = make_dataset(\"test\")\nprint(f\"Train/Val/Test: {len(train_files)}/{len(val_files)}/{len(test_files)}\")\n\n# Transforms\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\",\"label\"]),\n    EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0, b_max=1, clip=True),\n    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),\n    RandCropByPosNegLabeld(keys=[\"image\",\"label\"], label_key=\"label\", spatial_size=train_roi_size,\n                             pos=1, neg=1, num_samples=4),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[0], prob=0.1),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[1], prob=0.1),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[2], prob=0.1),\n    RandRotate90d(keys=[\"image\",\"label\"], prob=0.1, max_k=3),\n    RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n    EnsureTyped(keys=[\"image\",\"label\"], track_meta=False),\n])\nval_transforms = Compose([\n    LoadImaged(keys=[\"image\",\"label\"]),\n    EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0, b_max=1, clip=True),\n    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),\n    EnsureTyped(keys=[\"image\",\"label\"], track_meta=True),\n])\n\n# DataLoaders\ndata_train = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\ndata_val = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\ntrain_loader = DataLoader(data_train, batch_size=train_batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(data_val, batch_size=val_batch_size, shuffle=False, num_workers=4)\n\ntest_ds = Dataset(data=test_files, transform=val_transforms)\ntest_loader = DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=4)\n\n# Define UNet++ with gradient checkpointing\nimport torch.nn as nn\nimport torch.utils.checkpoint as cp\n\ndef conv_block(in_ch, out_ch):\n    return nn.Sequential(\n        nn.Conv3d(in_ch, out_ch, 3, padding=1, bias=False),\n        nn.BatchNorm3d(out_ch),\n        nn.ReLU(inplace=True),\n        nn.Conv3d(out_ch, out_ch, 3, padding=1, bias=False),\n        nn.BatchNorm3d(out_ch),\n        nn.ReLU(inplace=True)\n    )\n\nclass UNetPlusPlus3D(nn.Module):\n    def __init__(self, filters=(8,16,32,64)):\n        super().__init__()\n        f = filters\n        self.conv0_0 = conv_block(1, f[0]); self.conv1_0 = conv_block(f[0], f[1])\n        self.conv2_0 = conv_block(f[1], f[2]); self.conv3_0 = conv_block(f[2], f[3])\n        self.conv0_1 = conv_block(f[0]+f[1], f[0]); self.conv1_1 = conv_block(f[1]+f[2], f[1]); self.conv2_1 = conv_block(f[2]+f[3], f[2])\n        self.conv0_2 = conv_block(f[0]*2+f[1], f[0]); self.conv1_2 = conv_block(f[1]*2+f[2], f[1])\n        self.conv0_3 = conv_block(f[0]*3+f[1], f[0])\n        self.pool = nn.MaxPool3d(2)\n        self.up = lambda x, ref: nn.functional.interpolate(x, size=ref.shape[2:], mode='trilinear', align_corners=True)\n        self.final = nn.Conv3d(f[0], 2, 1)\n\n    def forward(self, x):\n        x0_0 = cp.checkpoint(self.conv0_0, x)\n        x1_0 = cp.checkpoint(self.conv1_0, self.pool(x0_0))\n        x0_1 = cp.checkpoint(self.conv0_1, torch.cat([x0_0, self.up(x1_0, x0_0)], dim=1))\n        x2_0 = cp.checkpoint(self.conv2_0, self.pool(x1_0))\n        x1_1 = cp.checkpoint(self.conv1_1, torch.cat([x1_0, self.up(x2_0, x1_0)], dim=1))\n        x0_2 = cp.checkpoint(self.conv0_2, torch.cat([x0_0, x0_1, self.up(x1_1, x0_0)], dim=1))\n        x3_0 = cp.checkpoint(self.conv3_0, self.pool(x2_0))\n        x2_1 = cp.checkpoint(self.conv2_1, torch.cat([x2_0, self.up(x3_0, x2_0)], dim=1))\n        x1_2 = cp.checkpoint(self.conv1_2, torch.cat([x1_0, x1_1, self.up(x2_1, x1_0)], dim=1))\n        x0_3 = cp.checkpoint(self.conv0_3, torch.cat([x0_0, x0_1, x0_2, self.up(x1_2, x0_0)], dim=1))\n        return self.final(x0_3)\n\nmodel = UNetPlusPlus3D().to(device)\n\n# Optimizer & Loss\noptimizer = Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, 'max', patience=patience, factor=0.5, verbose=True)\nloss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\")\nscaler = GradScaler()\n\n# Training & Validation\nbest_metric, best_epoch, no_improve = -1.0, -1, 0\nfor epoch in range(1, max_epochs+1):\n    model.train(); train_loss=0.0\n    for i, batch in enumerate(train_loader, 1):\n        imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n        optimizer.zero_grad()\n        with autocast():\n            preds = model(imgs)\n            loss = loss_fn(preds, lbls)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        train_loss += loss.item()\n    print(f\"Epoch {epoch} | Train Loss: {train_loss/i:.4f}\")\n\n    model.eval(); dice_metric.reset()\n    with torch.no_grad(), autocast():\n        for batch in val_loader:\n            imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n            out = sliding_window_inference(\n                imgs, roi_size=infer_roi_size, sw_batch_size=1, predictor=model, overlap=0.5\n            )\n            seg = torch.argmax(out.softmax(1), 1)\n            onehot_pred = F.one_hot(seg, 2).permute(0,4,1,2,3).float()\n            gt = lbls.squeeze(1).long()\n            onehot_gt = F.one_hot(gt, 2).permute(0,4,1,2,3).float()\n            for b in range(onehot_pred.shape[0]):\n                dice_metric(y_pred=[onehot_pred[b]], y=[onehot_gt[b]])\n    val_dice = dice_metric.aggregate().item()\n    print(f\"Epoch {epoch} | Val Dice: {val_dice:.4f}\")\n    scheduler.step(val_dice)\n\n    if val_dice > best_metric:\n        best_metric, best_epoch, no_improve = val_dice, epoch, 0\n        best_ckpt = os.path.join(checkpoint_dir, f\"best_epoch{epoch}.pth\")\n        torch.save(model.state_dict(), best_ckpt)\n        print(f\"Saved best model: {best_ckpt}\")\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    if epoch % save_interval == 0:\n        ckpt = os.path.join(checkpoint_dir, f\"ckpt_epoch{epoch}.pth\")\n        torch.save(model.state_dict(), ckpt)\n        print(f\"Saved periodic checkpoint: {ckpt}\")\n\nprint(f\"Training done | Best Val Dice: {best_metric:.4f} at epoch {best_epoch}\")\n\n# Test Phase\nprint(\"\\n--- Testing on held-out set ---\")\nmodel.load_state_dict(torch.load(best_ckpt, map_location=device))\nmodel.eval(); dice_metric.reset()\nwith torch.no_grad(), autocast():\n    for batch in test_loader:\n        imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n        out = sliding_window_inference(\n            imgs, roi_size=infer_roi_size, sw_batch_size=1, predictor=model, overlap=0.5\n        )\n        seg = torch.argmax(out.softmax(1), 1)\n        onehot_pred = F.one_hot(seg, 2).permute(0,4,1,2,3).float()\n        gt = lbls.squeeze(1).long()\n        onehot_gt = F.one_hot(gt, 2).permute(0,4,1,2,3).float()\n        for b in range(onehot_pred.shape[0]):\n            dice_metric(y_pred=[onehot_pred[b]], y=[onehot_gt[b]])\nfinal_test_dice = dice_metric.aggregate().item()\nprint(f\"Test Mean Dice: {final_test_dice:.4f}\")\n\n# Plot\nprint(\"\\n--- Sample Predictions ---\")\nplot_count = 0\nfor batch in val_loader:\n    if plot_count >= 3: break\n    img_np = batch['image'][0,0].cpu().numpy()\n    lbl_np = batch['label'][0,0].cpu().numpy()\n    with torch.no_grad(), autocast():\n        out = sliding_window_inference(\n            batch['image'].to(device), roi_size=infer_roi_size, sw_batch_size=1, predictor=model, overlap=0.5\n        )\n        pred_np = torch.argmax(out.softmax(1), 1)[0].cpu().numpy()\n    slice_idx = img_np.shape[2] // 2\n    plt.figure(figsize=(12,4))\n    plt.subplot(1,3,1); plt.imshow(img_np[:,:,slice_idx], cmap=\"gray\"); plt.title(\"Image\"); plt.axis('off')\n    plt.subplot(1,3,2); plt.imshow(lbl_np[:,:,slice_idx]); plt.title(\"Label\"); plt.axis('off')\n    plt.subplot(1,3,3); plt.imshow(pred_np[:,:,slice_idx]); plt.title(\"Prediction\"); plt.axis('off')\n    plt.tight_layout(); plt.show()\n    plot_count += 1\nprint(\"Done.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:01:14.887564Z","iopub.execute_input":"2025-04-28T16:01:14.887938Z","iopub.status.idle":"2025-04-28T16:24:45.239383Z","shell.execute_reply.started":"2025-04-28T16:01:14.887906Z","shell.execute_reply":"2025-04-28T16:24:45.238331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.cuda.amp import autocast, GradScaler\nimport matplotlib.pyplot as plt\n\n# MONAI imports\nfrom monai.data import CacheDataset, Dataset, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd,\n    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld,\n    RandFlipd, RandRotate90d, RandShiftIntensityd,\n    EnsureTyped, Compose\n)\nfrom monai.losses import DiceCELoss\nfrom monai.metrics import DiceMetric\nfrom monai.config import print_config\nfrom monai.utils import set_determinism\n\n# Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint_config(); print(f\"Using device: {device}\")\n\n# Reproducibility\nseed = 42\nset_determinism(seed=seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Hyperparameters\nmax_epochs = 300\ntrain_batch_size = 1\nval_batch_size = 1\ntest_batch_size = 1\nlearning_rate = 5e-5\npatience = 20\ntrain_roi_size = (64, 64, 64)\ninfer_roi_size = (128, 128, 128)\nsave_interval = 20  # periodic model save\nresume_interval = 20  # periodic resume checkpoint\n\n# Paths\nbase_data_dir = \"/kaggle/input/spleen\"\ndata_root = os.path.join(base_data_dir, \"data\", \"Spleen\")\ncheckpoint_dir = \"/kaggle/working/checkpoints_attunet++\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n# Dataset helper\ndef make_dataset(phase):\n    img_dir = os.path.join(data_root, phase, \"images\")\n    lbl_dir = os.path.join(data_root, phase, \"labels\")\n    imgs = sorted(glob.glob(os.path.join(img_dir, \"*.nii*\")))\n    lbls = sorted(glob.glob(os.path.join(lbl_dir, \"*.nii*\")))\n    assert len(imgs) == len(lbls) and len(imgs) > 0, f\"Data error in {phase}\"\n    return [{\"image\": i, \"label\": l} for i, l in zip(imgs, lbls)]\n\ntrain_files = make_dataset(\"train\")\nval_files = make_dataset(\"val\")\ntest_files = make_dataset(\"test\")\nprint(f\"Train/Val/Test: {len(train_files)}/{len(val_files)}/{len(test_files)}\")\n\n# Transforms\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\",\"label\"]), EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57,a_max=164,b_min=0,b_max=1,clip=True),\n    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),\n    RandCropByPosNegLabeld(keys=[\"image\",\"label\"],label_key=\"label\",spatial_size=train_roi_size,pos=1,neg=1,num_samples=4),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[0], prob=0.1),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[1], prob=0.1),\n    RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[2], prob=0.1),\n    RandRotate90d(keys=[\"image\",\"label\"], prob=0.1, max_k=3),\n    RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n    EnsureTyped(keys=[\"image\",\"label\"], track_meta=False),\n])\nval_transforms = Compose([\n    LoadImaged(keys=[\"image\",\"label\"]), EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.5,1.5,2.0), mode=(\"bilinear\",\"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57,a_max=164,b_min=0,b_max=1,clip=True),\n    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),\n    EnsureTyped(keys=[\"image\",\"label\"], track_meta=True),\n])\n\n# DataLoaders\ndata_train = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\ntrain_loader = DataLoader(data_train, batch_size=train_batch_size, shuffle=True, num_workers=4)\ndata_val = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\nval_loader = DataLoader(data_val, batch_size=val_batch_size, shuffle=False, num_workers=4)\ntest_ds = Dataset(data=test_files, transform=val_transforms)\ntest_loader = DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=4)\n\n# Attention U-Net definition\nfrom monai.networks.nets import AttentionUnet\n\nmodel = AttentionUnet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=2,\n    channels=(8, 16, 32, 64),   # adjust for memory vs performance\n    strides=(2, 2, 2),\n    kernel_size=3,\n    up_kernel_size=3,\n    dropout=0.0,\n).to(device)\n\n# Optimizer & utilities\noptimizer = Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer,'max',patience=patience,factor=0.5,verbose=True)\nloss_fn = DiceCELoss(to_onehot_y=True,softmax=True)\ndice_metric = DiceMetric(include_background=False,reduction='mean')\nscaler = GradScaler()\n\n# Resume logic\nstart_epoch = 1\nbest_metric = -1.0\nbest_epoch = 0\nno_improve = 0\nlatest_ckpt = os.path.join(checkpoint_dir,'latest.pth')\nif os.path.exists(latest_ckpt):\n    ckpt = torch.load(latest_ckpt,map_location=device)\n    model.load_state_dict(ckpt['model'])\n    optimizer.load_state_dict(ckpt['optimizer'])\n    scheduler.load_state_dict(ckpt['scheduler'])\n    scaler.load_state_dict(ckpt['scaler'])\n    best_metric = ckpt['best_metric']; best_epoch = ckpt['best_epoch']; no_improve = ckpt['no_improve']\n    start_epoch = ckpt['epoch'] + 1\n    print(f\"Resumed from epoch {start_epoch-1}\")\n\n# Training loop\nfor epoch in range(start_epoch, max_epochs+1):\n    model.train(); sum_loss=0.0\n    for i,batch in enumerate(train_loader,1):\n        imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n        optimizer.zero_grad()\n        with autocast():\n            preds = model(imgs)\n            loss = loss_fn(preds,lbls)\n        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n        sum_loss += loss.item()\n    print(f\"Epoch {epoch} | Train Loss: {sum_loss/i:.4f}\")\n\n    model.eval(); dice_metric.reset()\n    with torch.no_grad(), autocast():\n        for batch in val_loader:\n            imgs, lbls = batch['image'].to(device), batch['label'].to(device)\n            out = sliding_window_inference(imgs, roi_size=infer_roi_size, sw_batch_size=1, predictor=model, overlap=0.5)\n            seg = torch.argmax(out.softmax(1),1)\n            oh = F.one_hot(seg,2).permute(0,4,1,2,3).float()\n            gt = lbls.squeeze(1).long()\n            ohg = F.one_hot(gt,2).permute(0,4,1,2,3).float()\n            for b in range(oh.shape[0]): dice_metric(y_pred=[oh[b]],y=[ohg[b]])\n    val_dice = dice_metric.aggregate().item()\n    print(f\"Epoch {epoch} | Val Dice: {val_dice:.4f}\")\n    scheduler.step(val_dice)\n\n    # best model\n    if val_dice>best_metric:\n        best_metric,best_epoch,no_improve=val_dice,epoch,0\n        best_path=os.path.join(checkpoint_dir,f\"best_epoch{epoch}.pth\")\n        torch.save(model.state_dict(),best_path)\n        print(f\"Saved best model: {best_path}\")\n    else:\n        no_improve+=1\n        if no_improve>=patience:\n            print(\"Early stopping.\")\n            break\n\n    # periodic checkpoint\n    if epoch%save_interval==0:\n        path=os.path.join(checkpoint_dir,f\"ckpt_epoch{epoch}.pth\")\n        torch.save(model.state_dict(),path)\n        print(f\"Saved periodic: {path}\")\n\n    # resume checkpoint\n    if epoch%resume_interval==0:\n        torch.save({\n            'epoch':epoch,\n            'model':model.state_dict(),\n            'optimizer':optimizer.state_dict(),\n            'scheduler':scheduler.state_dict(),\n            'scaler':scaler.state_dict(),\n            'best_metric':best_metric,\n            'best_epoch':best_epoch,\n            'no_improve':no_improve\n        }, latest_ckpt)\n        print(f\"Saved resume checkpoint: {latest_ckpt}\")\n\nprint(f\"Training done | Best Val Dice: {best_metric:.4f} at epoch {best_epoch}\")\n\n# Test phase\nprint(\"\\n--- Testing ---\")\nmodel.load_state_dict(torch.load(best_path,map_location=device))\nmodel.eval(); dice_metric.reset()\nwith torch.no_grad(), autocast():\n    for batch in test_loader:\n        imgs,lbls = batch['image'].to(device), batch['label'].to(device)\n        out = sliding_window_inference(imgs,roi_size=infer_roi_size,sw_batch_size=1,predictor=model,overlap=0.5)\n        seg=torch.argmax(out.softmax(1),1)\n        oh=F.one_hot(seg,2).permute(0,4,1,2,3).float()\n        gt=lbls.squeeze(1).long()\n        ohg=F.one_hot(gt,2).permute(0,4,1,2,3).float()\n        for b in range(oh.shape[0]): dice_metric(y_pred=[oh[b]],y=[ohg[b]])\nfinal= dice_metric.aggregate().item()\nprint(f\"Test Mean Dice: {final:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T20:20:02.897364Z","iopub.execute_input":"2025-04-28T20:20:02.897837Z","iopub.status.idle":"2025-04-28T20:25:26.512562Z","shell.execute_reply.started":"2025-04-28T20:20:02.897796Z","shell.execute_reply":"2025-04-28T20:25:26.511474Z"}},"outputs":[{"name":"stdout","text":"MONAI version: 1.4.1rc1+46.gb58e883c\nNumpy version: 1.26.4\nPytorch version: 2.5.1+cu121\nMONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\nMONAI rev id: b58e883c887e0f99d382807550654c44d94f47bd\nMONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n\nOptional dependencies:\nPytorch Ignite version: 0.5.1\nITK version: NOT INSTALLED or UNKNOWN VERSION.\nNibabel version: 5.3.2\nscikit-image version: 0.25.0\nscipy version: 1.13.1\nPillow version: 11.0.0\nTensorboard version: 2.17.1\ngdown version: 5.2.0\nTorchVision version: 0.20.1+cu121\ntqdm version: 4.67.1\nlmdb version: NOT INSTALLED or UNKNOWN VERSION.\npsutil version: 5.9.5\npandas version: 2.2.3\neinops version: 0.8.0\ntransformers version: 4.47.0\nmlflow version: NOT INSTALLED or UNKNOWN VERSION.\npynrrd version: NOT INSTALLED or UNKNOWN VERSION.\nclearml version: NOT INSTALLED or UNKNOWN VERSION.\n\nFor details about installing the optional dependencies, please visit:\n    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n\nUsing device: cuda\nTrain/Val/Test: 29/6/6\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 29/29 [00:48<00:00,  1.68s/it]\nLoading dataset: 100%|██████████| 6/6 [00:09<00:00,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"Resumed from epoch 120\n","output_type":"stream"},{"name":"stderr","text":"\n<ipython-input-6-4239e8520624>:120: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n<ipython-input-6-4239e8520624>:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(latest_ckpt,map_location=device)\n<ipython-input-6-4239e8520624>:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch 121 | Train Loss: 0.7981\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-4239e8520624>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.no_grad(), autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch 121 | Val Dice: 0.3760\nEpoch 122 | Train Loss: 0.8224\nEpoch 122 | Val Dice: 0.4063\nEpoch 123 | Train Loss: 0.8217\nEpoch 123 | Val Dice: 0.4605\nEpoch 124 | Train Loss: 0.8171\nEpoch 124 | Val Dice: 0.4526\nEpoch 125 | Train Loss: 0.8034\nEpoch 125 | Val Dice: 0.4158\nEpoch 126 | Train Loss: 0.8210\nEpoch 126 | Val Dice: 0.4510\nEarly stopping.\nTraining done | Best Val Dice: 0.5279 at epoch 106\n\n--- Testing ---\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-4239e8520624>:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(best_path,map_location=device))\n<ipython-input-6-4239e8520624>:203: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.no_grad(), autocast():\n","output_type":"stream"},{"name":"stdout","text":"Test Mean Dice: 0.3852\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.swa_utils import AveragedModel, SWALR, update_bn\nfrom monai.data import CacheDataset, Dataset, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld,\n    RandFlipd, RandRotate90d, RandShiftIntensityd,\n    RandGaussianNoised, Rand3DElasticd,\n    EnsureTyped, Compose\n)\nfrom monai.losses import TverskyLoss\nfrom monai.metrics import DiceMetric\nfrom monai.networks.nets import UNet\nfrom monai.config import print_config\nfrom monai.utils import set_determinism\nimport time\n\n# -------------------- Configuration --------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint_config()\nprint(f\"Using device: {device}\")\n\nseed = 42\nset_determinism(seed=seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\ndata_root = \"/kaggle/input/spleen/data/Spleen\"\ncheckpoint_dir = \"/kaggle/working/checkpoints_unet_swa\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\nmax_epochs = 200\ntrain_batch_size = 2\nval_batch_size = 1\ntest_batch_size = 1\nlearning_rate = 1e-3\ntrain_roi_size = (128, 128, 128)\ninfer_roi_size = (192, 192, 192)\npatience = 30\naccumulation_steps = 2\nswa_start_epoch = int(max_epochs * 0.75)\nsave_every = 15\n\n# -------------------- Dataset --------------------\ndef make_dataset(phase):\n    img_dir = os.path.join(data_root, phase, \"images\")\n    lbl_dir = os.path.join(data_root, phase, \"labels\")\n    imgs = sorted(glob.glob(os.path.join(img_dir, \"*.nii*\")))\n    lbls = sorted(glob.glob(os.path.join(lbl_dir, \"*.nii*\")))\n    assert len(imgs) == len(lbls) and len(imgs) > 0, f\"Data error in {phase}\"\n    return [{\"image\": i, \"label\": l} for i, l in zip(imgs, lbls)]\n\ntrain_files = make_dataset(\"train\")\nval_files = make_dataset(\"val\")\ntest_files = make_dataset(\"test\")\nprint(f\"Train/Val/Test: {len(train_files)}/{len(val_files)}/{len(test_files)}\")\n\n# -------------------- Transforms --------------------\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    RandCropByPosNegLabeld(\n        keys=[\"image\", \"label\"], label_key=\"label\",\n        spatial_size=train_roi_size, pos=1, neg=1, num_samples=8,\n        allow_smaller=True\n    ),\n    RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0, 1, 2], prob=0.5),\n    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, max_k=3),\n    RandShiftIntensityd(keys=[\"image\"], offsets=0.15, prob=0.5),\n    RandGaussianNoised(keys=[\"image\"], prob=0.3, mean=0.0, std=0.1),\n    Rand3DElasticd(keys=[\"image\", \"label\"], sigma_range=(5, 8), magnitude_range=(100, 200),\n                   spatial_size=train_roi_size, prob=0.3, mode=(\"bilinear\", \"nearest\")),\n    EnsureTyped(keys=[\"image\", \"label\"], track_meta=False),\n])\nval_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    EnsureTyped(keys=[\"image\", \"label\"], track_meta=True),\n])\n\n# -------------------- DataLoaders --------------------\ntrain_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\ntrain_loader = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True, num_workers=4)\nval_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=2)\ntest_ds = Dataset(data=test_files, transform=val_transforms)\ntest_loader = DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=2)\n\n# -------------------- Model & Optimization --------------------\nmodel = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=2,\n    channels=(32, 64, 128, 256, 512),\n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n    dropout=0.1\n).to(device)\noptimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = CosineAnnealingLR(optimizer, T_max=max_epochs - swa_start_epoch, eta_min=1e-6)\nloss_fn = TverskyLoss(alpha=0.3, beta=0.7, to_onehot_y=True, smooth_nr=1e-5, smooth_dr=1e-5)\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\")\nscaler = GradScaler()\n\nswa_model = AveragedModel(model)\nswa_scheduler = SWALR(optimizer, swa_lr=learning_rate * 0.1)\n\n# -------------------- Resume from latest checkpoint --------------------\nstart_epoch = 1\nbest_metric = -1.0\ncheckpoint_files = sorted(glob.glob(os.path.join(checkpoint_dir, \"checkpoint_epoch*.pth\")))\nif checkpoint_files:\n    latest_checkpoint = checkpoint_files[-1]\n    print(f\"Resuming training from {latest_checkpoint}\")\n    checkpoint = torch.load(latest_checkpoint, map_location=device)\n    model.load_state_dict(checkpoint[\"model_state\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n    scaler.load_state_dict(checkpoint[\"scaler_state\"])\n    scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n    start_epoch = checkpoint[\"epoch\"] + 1\n    best_metric = checkpoint.get(\"best_metric\", -1.0)\nelse:\n    print(\"No checkpoint found. Starting training from scratch.\")\n\n# -------------------- Training & Validation --------------------\nbest_epoch, no_improve = 0, 0\nfor epoch in range(start_epoch, max_epochs + 1):\n    epoch_start = time.time()\n    model.train()\n    epoch_loss = 0.0\n    optimizer.zero_grad()\n    for i, batch in enumerate(train_loader, 1):\n        imgs = batch['image'].to(device)\n        lbls = batch['label'].to(device)\n        with autocast():\n            outputs = model(imgs)\n            loss = loss_fn(outputs, lbls) / accumulation_steps\n        scaler.scale(loss).backward()\n        if i % accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        epoch_loss += float(loss) * accumulation_steps\n        if epoch <= swa_start_epoch:\n            scheduler.step()\n        else:\n            swa_scheduler.step()\n    epoch_loss /= i\n    print(f\"Epoch {epoch} | Train Loss: {epoch_loss:.4f}\")\n\n    if epoch > swa_start_epoch:\n        swa_model.update_parameters(model)\n\n    # Validation\n    eval_model = swa_model.module if epoch > swa_start_epoch else model\n    eval_model.eval()\n    dice_metric.reset()\n    with torch.no_grad():\n        for batch in val_loader:\n            imgs = batch['image'].to(device)\n            lbls = batch['label'].to(device)\n            out = sliding_window_inference(\n                imgs, roi_size=infer_roi_size, sw_batch_size=1,\n                predictor=eval_model, overlap=0.5\n            )\n            seg = torch.argmax(torch.softmax(out, dim=1), dim=1)\n            oh = F.one_hot(seg, num_classes=2).permute(0, 4, 1, 2, 3).float()\n            gt = lbls.squeeze(1).long()\n            ohg = F.one_hot(gt, num_classes=2).permute(0, 4, 1, 2, 3).float()\n            for b in range(oh.shape[0]):\n                dice_metric(y_pred=[oh[b]], y=[ohg[b]])\n    val_dice = float(dice_metric.aggregate())\n    print(f\"Epoch {epoch} | Val Dice: {val_dice:.4f}\")\n\n    if val_dice > best_metric:\n        best_metric, best_epoch, no_improve = val_dice, epoch, 0\n        torch.save({\n            \"model_state\": eval_model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n            \"scaler_state\": scaler.state_dict(),\n            \"scheduler_state\": scheduler.state_dict(),\n            \"epoch\": epoch,\n            \"best_metric\": best_metric\n        }, os.path.join(checkpoint_dir, f\"best_epoch{epoch}.pth\"))\n        print(f\"Saved best model at epoch {epoch}\")\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    if epoch % save_every == 0:\n        torch.save({\n            \"model_state\": model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n            \"scaler_state\": scaler.state_dict(),\n            \"scheduler_state\": scheduler.state_dict(),\n            \"epoch\": epoch,\n            \"best_metric\": best_metric\n        }, os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pth\"))\n        print(f\"Saved checkpoint at epoch {epoch}\")\n\nprint(f\"Training complete. Best Val Dice: {best_metric:.4f} at epoch {best_epoch}\")\n\nupdate_bn(train_loader, swa_model, device=device)\n\n# -------------------- Testing --------------------\nprint(\"--- Testing ---\")\ncheckpoint = torch.load(os.path.join(checkpoint_dir, f\"best_epoch{best_epoch}.pth\"))\nmodel.load_state_dict(checkpoint[\"model_state\"])\nmodel.eval()\ndice_metric.reset()\nwith torch.no_grad():\n    for batch in test_loader:\n        imgs = batch['image'].to(device)\n        lbls = batch['label'].to(device)\n        out = sliding_window_inference(\n            imgs, roi_size=infer_roi_size, sw_batch_size=1,\n            predictor=swa_model.module, overlap=0.5\n        )\n        seg = torch.argmax(torch.softmax(out, dim=1), dim=1)\n        oh = F.one_hot(seg, num_classes=2).permute(0, 4, 1, 2, 3).float()\n        gt = lbls.squeeze(1).long()\n        ohg = F.one_hot(gt, num_classes=2).permute(0, 4, 1, 2, 3).float()\n        for b in range(oh.shape[0]):\n            dice_metric(y_pred=[oh[b]], y=[ohg[b]])\nfinal_dice = float(dice_metric.aggregate())\nprint(f\"Test Mean Dice: {final_dice:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:32:12.962238Z","iopub.execute_input":"2025-04-28T22:32:12.962588Z","iopub.status.idle":"2025-04-29T00:34:41.422236Z","shell.execute_reply.started":"2025-04-28T22:32:12.962560Z","shell.execute_reply":"2025-04-29T00:34:41.421111Z"}},"outputs":[{"name":"stdout","text":"MONAI version: 1.4.1rc1+46.gb58e883c\nNumpy version: 1.26.4\nPytorch version: 2.5.1+cu121\nMONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\nMONAI rev id: b58e883c887e0f99d382807550654c44d94f47bd\nMONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n\nOptional dependencies:\nPytorch Ignite version: 0.5.1\nITK version: NOT INSTALLED or UNKNOWN VERSION.\nNibabel version: 5.3.2\nscikit-image version: 0.25.0\nscipy version: 1.13.1\nPillow version: 11.0.0\nTensorboard version: 2.17.1\ngdown version: 5.2.0\nTorchVision version: 0.20.1+cu121\ntqdm version: 4.67.1\nlmdb version: NOT INSTALLED or UNKNOWN VERSION.\npsutil version: 5.9.5\npandas version: 2.2.3\neinops version: 0.8.0\ntransformers version: 4.47.0\nmlflow version: NOT INSTALLED or UNKNOWN VERSION.\npynrrd version: NOT INSTALLED or UNKNOWN VERSION.\nclearml version: NOT INSTALLED or UNKNOWN VERSION.\n\nFor details about installing the optional dependencies, please visit:\n    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n  warn_deprecated(argname, msg, warning_category)\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nTrain/Val/Test: 29/6/6\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 29/29 [00:51<00:00,  1.79s/it]\nLoading dataset: 100%|██████████| 6/6 [00:12<00:00,  2.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"No checkpoint found. Starting training from scratch.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-a68208664789>:121: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n<ipython-input-6-a68208664789>:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 0.6560\nEpoch 1 | Val Dice: 0.0326\nSaved best model at epoch 1\nEpoch 2 | Train Loss: 0.4045\nEpoch 2 | Val Dice: 0.0352\nSaved best model at epoch 2\nEpoch 3 | Train Loss: 0.2488\nEpoch 3 | Val Dice: 0.0314\nEpoch 4 | Train Loss: 0.1887\nEpoch 4 | Val Dice: 0.0350\nEpoch 5 | Train Loss: 0.1438\nEpoch 5 | Val Dice: 0.0495\nSaved best model at epoch 5\nEpoch 6 | Train Loss: 0.6568\nEpoch 6 | Val Dice: 0.0972\nSaved best model at epoch 6\nEpoch 7 | Train Loss: -0.1423\nEpoch 7 | Val Dice: 0.0379\nEpoch 8 | Train Loss: 0.5313\nEpoch 8 | Val Dice: 0.0909\nEpoch 9 | Train Loss: 0.6881\nEpoch 9 | Val Dice: 0.0853\nEpoch 10 | Train Loss: 1.0396\nEpoch 10 | Val Dice: 0.0881\nEpoch 11 | Train Loss: 0.9814\nEpoch 11 | Val Dice: 0.0872\nEpoch 12 | Train Loss: 0.9076\nEpoch 12 | Val Dice: 0.0708\nEpoch 13 | Train Loss: 0.7427\nEpoch 13 | Val Dice: 0.0342\nEpoch 14 | Train Loss: 0.6254\nEpoch 14 | Val Dice: 0.0058\nEpoch 15 | Train Loss: 0.5468\nEpoch 15 | Val Dice: 0.0003\nSaved checkpoint at epoch 15\nEpoch 16 | Train Loss: 0.5219\nEpoch 16 | Val Dice: 0.0002\nEpoch 17 | Train Loss: 0.5377\nEpoch 17 | Val Dice: 0.0002\nEpoch 18 | Train Loss: 0.5089\nEpoch 18 | Val Dice: 0.0001\nEpoch 19 | Train Loss: 0.4989\nEpoch 19 | Val Dice: 0.0000\nEpoch 20 | Train Loss: 0.4892\nEpoch 20 | Val Dice: 0.0000\nEpoch 21 | Train Loss: 0.4539\nEpoch 21 | Val Dice: 0.0000\nEpoch 22 | Train Loss: 0.4040\nEpoch 22 | Val Dice: 0.0000\nEpoch 23 | Train Loss: -0.1879\nEpoch 23 | Val Dice: 0.0001\nEpoch 24 | Train Loss: 0.2726\nEpoch 24 | Val Dice: 0.0001\nEpoch 25 | Train Loss: 1.1418\nEpoch 25 | Val Dice: 0.0002\nEpoch 26 | Train Loss: 0.8666\nEpoch 26 | Val Dice: 0.0075\nEpoch 27 | Train Loss: 0.7240\nEpoch 27 | Val Dice: 0.0169\nEpoch 28 | Train Loss: 0.7079\nEpoch 28 | Val Dice: 0.0177\nEpoch 29 | Train Loss: 0.7038\nEpoch 29 | Val Dice: 0.0178\nEpoch 30 | Train Loss: 0.7013\nEpoch 30 | Val Dice: 0.0178\nSaved checkpoint at epoch 30\nEpoch 31 | Train Loss: 0.6997\nEpoch 31 | Val Dice: 0.0178\nEpoch 32 | Train Loss: 0.6999\nEpoch 32 | Val Dice: 0.0177\nEpoch 33 | Train Loss: 0.7006\nEpoch 33 | Val Dice: 0.0177\nEpoch 34 | Train Loss: 0.7004\nEpoch 34 | Val Dice: 0.0176\nEpoch 35 | Train Loss: 0.6987\nEpoch 35 | Val Dice: 0.0176\nEpoch 36 | Train Loss: 0.6974\nEpoch 36 | Val Dice: 0.0176\nEarly stopping triggered.\nTraining complete. Best Val Dice: 0.0972 at epoch 6\n--- Testing ---\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-a68208664789>:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(os.path.join(checkpoint_dir, f\"best_epoch{best_epoch}.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Test Mean Dice: 0.0106\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"GAN","metadata":{}},{"cell_type":"code","source":"import os, re\nimport nibabel as nib\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.functional import pad\nfrom torch.amp import autocast, GradScaler\nfrom tqdm import tqdm\n\n# ----------------------------\n# 0) CONFIGURATION\n# ----------------------------\nDATA_DIR         = \"/kaggle/input/spleen/data/Spleen\"\nCKPT_DIR         = \"/kaggle/working/gan_checkpoints\"\nos.makedirs(CKPT_DIR, exist_ok=True)\n\nBATCH_SIZE       = 1\nEPOCHS           = 50\nLR               = 2e-4\nCHECKPOINT_EVERY = 10\nDEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSCALER           = GradScaler()\n\n# Desired volume shape (D, H, W)\nTARGET_SHAPE     = (50, 512, 512)\n\n\n# ----------------------------\n# 1) DATASET\n# ----------------------------\nclass NiiDataset(Dataset):\n    def __init__(self, base_dir, split=\"train\"):\n        self.img_dir = os.path.join(base_dir, split, \"images\")\n        self.lbl_dir = os.path.join(base_dir, split, \"labels\")\n        self.files   = sorted(f for f in os.listdir(self.img_dir) if f.endswith(\".nii\"))\n\n    def __len__(self):\n        return len(self.files)\n\n    def _process(self, vol_np):\n        vol = torch.from_numpy(vol_np.transpose(2,0,1)).float()\n        # center‐crop if too large\n        for ax, tgt in enumerate(TARGET_SHAPE):\n            if vol.size(ax) > tgt:\n                start = (vol.size(ax) - tgt)//2\n                vol = vol.narrow(ax, start, tgt)\n        # pad if too small\n        pads = []\n        for sz, tgt in zip(vol.shape, TARGET_SHAPE):\n            diff = tgt - sz\n            b = diff//2 if diff>0 else 0\n            a = diff - b if diff>0 else 0\n            pads.extend([b, a])\n        vol = pad(vol, pads[::-1], mode=\"constant\", value=0.0)\n        return vol.unsqueeze(0)\n\n    def __getitem__(self, idx):\n        fn   = self.files[idx]\n        img  = nib.load(os.path.join(self.img_dir, fn)).get_fdata()\n        mask = nib.load(os.path.join(self.lbl_dir, fn)).get_fdata()\n        img  = (img - img.min()) / (img.max() - img.min() + 1e-8)\n        return self._process(img), self._process(mask)\n\n\n# ----------------------------\n# 2) MODELS (no final Sigmoid)\n# ----------------------------\nclass UNet3D(nn.Module):\n    def __init__(self, in_ch=1, out_ch=1):\n        super().__init__()\n        def C(ic, oc):\n            return nn.Sequential(\n                nn.Conv3d(ic,  oc, 3, padding=1), nn.BatchNorm3d(oc), nn.ReLU(inplace=True),\n                nn.Conv3d(oc, oc, 3, padding=1),   nn.BatchNorm3d(oc), nn.ReLU(inplace=True),\n            )\n        self.enc1 = C(in_ch,   32)\n        self.enc2 = C(32,      64)\n        self.enc3 = C(64,     128)\n        self.pool = nn.MaxPool3d(2)\n        self.up2  = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=(1,0,0))\n        self.dec2 = C(64+64,   64)\n        self.up1  = nn.ConvTranspose3d(64,  32, kernel_size=2, stride=2)\n        self.dec1 = C(32+32,   32)\n        self.final= nn.Conv3d(32, out_ch, 1)  # raw logits\n\n    def forward(self, x):\n        c1 = self.enc1(x); p1 = self.pool(c1)\n        c2 = self.enc2(p1); p2 = self.pool(c2)\n        c3 = self.enc3(p2)\n\n        u2 = self.up2(c3)\n        diff = [c2.size(i+2) - u2.size(i+2) for i in range(3)]\n        slices = []\n        for i, d in enumerate(diff):\n            if d>0:\n                s = d//2\n                slices.append(slice(s, s+u2.size(i+2)))\n            else:\n                slices.append(slice(None))\n        c2c = c2[:,:, slices[0], slices[1], slices[2]]\n        d2  = self.dec2(torch.cat([u2, c2c], dim=1))\n\n        u1 = self.up1(d2)\n        diff = [c1.size(i+2) - u1.size(i+2) for i in range(3)]\n        slices = []\n        for i, d in enumerate(diff):\n            if d>0:\n                s = d//2\n                slices.append(slice(s, s+u1.size(i+2)))\n            else:\n                slices.append(slice(None))\n        c1c = c1[:,:, slices[0], slices[1], slices[2]]\n        d1  = self.dec1(torch.cat([u1, c1c], dim=1))\n\n        return self.final(d1)  # logits\n\n\nclass Disc3D(nn.Module):\n    def __init__(self, in_ch=2):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv3d(in_ch,  32, 4, stride=2, padding=1), nn.LeakyReLU(0.2, True),\n            nn.Conv3d(32,    64, 4, stride=2, padding=1), nn.BatchNorm3d(64), nn.LeakyReLU(0.2, True),\n            nn.Conv3d(64,   128, 4, stride=2, padding=1), nn.BatchNorm3d(128), nn.LeakyReLU(0.2, True),\n            nn.Conv3d(128,    1, 4, stride=1, padding=1)   # logits\n        )\n\n    def forward(self, x, y):\n        return self.net(torch.cat([x, y], dim=1))\n\n\n# ----------------------------\n# 3) SETUP & AUTO-RESUME\n# ----------------------------\ngen  = UNet3D().to(DEVICE)\ndisc = Disc3D().to(DEVICE)\nadv  = nn.BCEWithLogitsLoss()\nseg  = nn.BCEWithLogitsLoss()\noptG = optim.Adam(gen.parameters(),  lr=LR, betas=(0.5,0.999))\noptD = optim.Adam(disc.parameters(), lr=LR, betas=(0.5,0.999))\n\nstart_epoch = 0\nckpts = [int(m.group(1)) for fn in os.listdir(CKPT_DIR)\n         if (m := re.match(r\"ckpt_(\\d+)\\.pth\", fn))]\nif ckpts:\n    last = max(ckpts)\n    data = torch.load(os.path.join(CKPT_DIR, f\"ckpt_{last}.pth\"), map_location=DEVICE)\n    gen.load_state_dict(data[\"gen\"])\n    disc.load_state_dict(data[\"disc\"])\n    optG.load_state_dict(data[\"optG\"])\n    optD.load_state_dict(data[\"optD\"])\n    start_epoch = last\n    print(f\"→ Resumed from epoch {start_epoch}\")\n\ntrain_ds = NiiDataset(DATA_DIR, \"train\")\ntrain_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n                      num_workers=2, pin_memory=True)\n\n\n# ----------------------------\n# 4) TRAINING LOOP\n# ----------------------------\nfor ep in range(start_epoch, EPOCHS):\n    gen.train(); disc.train()\n    d_sum = g_sum = 0.0\n    bar = tqdm(train_ld, desc=f\"Epoch [{ep+1}/{EPOCHS}]\")\n    for imgs, real in bar:\n        imgs, real = imgs.to(DEVICE, non_blocking=True), real.to(DEVICE, non_blocking=True)\n\n        # -- Discriminator step --\n        optD.zero_grad()\n        with autocast(\"cuda\"):\n            pr    = disc(imgs, real)\n            fake  = gen(imgs)\n            pf    = disc(imgs, fake.detach())\n            d_loss= 0.5*(adv(pr, torch.ones_like(pr)) + adv(pf, torch.zeros_like(pf)))\n        SCALER.scale(d_loss).backward()\n        SCALER.step(optD)\n\n        # -- Generator step --\n        optG.zero_grad()\n        with autocast(\"cuda\"):\n            pf2    = disc(imgs, fake)\n            g_loss = adv(pf2, torch.ones_like(pf2)) + seg(fake, real)\n        SCALER.scale(g_loss).backward()\n        SCALER.step(optG)\n        SCALER.update()\n\n        d_sum += d_loss.item()\n        g_sum += g_loss.item()\n        bar.set_postfix(D=d_sum/len(train_ld), G=g_sum/len(train_ld))\n\n    # checkpoint every N epochs\n    if (ep+1) % CHECKPOINT_EVERY == 0 or (ep+1) == EPOCHS:\n        path = os.path.join(CKPT_DIR, f\"ckpt_{ep+1}.pth\")\n        torch.save({\n            \"gen\":  gen.state_dict(),\n            \"disc\": disc.state_dict(),\n            \"optG\": optG.state_dict(),\n            \"optD\": optD.state_dict(),\n        }, path)\n        print(f\"→ Saved checkpoint at epoch {ep+1}\")\n\n\n# ----------------------------\n# 5) FINAL EVALUATION\n# ----------------------------\ndef evaluate():\n    gen.eval()\n    ds   = NiiDataset(DATA_DIR, \"test\")\n    ld   = DataLoader(ds, batch_size=1, shuffle=False)\n    dices, ious = [], []\n    with torch.no_grad():\n        for imgs, real in tqdm(ld, desc=\"Eval\"):\n            imgs, real = imgs.to(DEVICE), real.to(DEVICE)\n            logits = gen(imgs)\n            probs  = torch.sigmoid(logits)\n            pred   = (probs > 0.5).float()\n            inter  = (pred * real).sum()\n            union  = pred.sum() + real.sum()\n            dices.append(((2*inter)/(union+1e-7)).item())\n            ious.append((inter/(union-inter+1e-7)).item())\n    print(f\"\\nFinal → Dice: {np.mean(dices):.4f}±{np.std(dices):.4f},  IoU: {np.mean(ious):.4f}±{np.std(ious):.4f}\")\n\nif __name__ == \"__main__\":\n    evaluate()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:17:58.174216Z","iopub.execute_input":"2025-04-29T12:17:58.174532Z","iopub.status.idle":"2025-04-29T14:06:30.568141Z","shell.execute_reply.started":"2025-04-29T12:17:58.174502Z","shell.execute_reply":"2025-04-29T14:06:30.567232Z"}},"outputs":[{"name":"stderr","text":"Epoch [1/50]: 100%|██████████| 29/29 [02:13<00:00,  4.60s/it, D=0.486, G=2.01] \nEpoch [2/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.183, G=3.23]  \nEpoch [3/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.102, G=3.65]  \nEpoch [4/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.0371, G=4.49] \nEpoch [5/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.0638, G=4.91] \nEpoch [6/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.233, G=4.74]   \nEpoch [7/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.116, G=4.32] \nEpoch [8/50]: 100%|██████████| 29/29 [02:10<00:00,  4.49s/it, D=0.0422, G=5.47]  \nEpoch [9/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.0664, G=5.41] \nEpoch [10/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.099, G=4.56]  \n","output_type":"stream"},{"name":"stdout","text":"→ Saved checkpoint at epoch 10\n","output_type":"stream"},{"name":"stderr","text":"Epoch [11/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.376, G=4.75]   \nEpoch [12/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.202, G=4.54] \nEpoch [13/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.108, G=5.36]   \nEpoch [14/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.332, G=3.93]  \nEpoch [15/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.321, G=3.48]  \nEpoch [16/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.319, G=3.7]  \nEpoch [17/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.294, G=3.47]  \nEpoch [18/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.302, G=3.4]  \nEpoch [19/50]: 100%|██████████| 29/29 [02:10<00:00,  4.49s/it, D=0.287, G=3.05] \nEpoch [20/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.399, G=2.63]  \n","output_type":"stream"},{"name":"stdout","text":"→ Saved checkpoint at epoch 20\n","output_type":"stream"},{"name":"stderr","text":"Epoch [21/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.408, G=2.61]   \nEpoch [22/50]: 100%|██████████| 29/29 [02:09<00:00,  4.46s/it, D=0.419, G=2.57]  \nEpoch [23/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.297, G=2.67] \nEpoch [24/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.263, G=2.68]  \nEpoch [25/50]: 100%|██████████| 29/29 [02:10<00:00,  4.50s/it, D=0.247, G=3.53]  \nEpoch [26/50]: 100%|██████████| 29/29 [02:09<00:00,  4.46s/it, D=0.386, G=2.86]  \nEpoch [27/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.263, G=2.96]  \nEpoch [28/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.346, G=2.93] \nEpoch [29/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.318, G=2.95]  \nEpoch [30/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.296, G=3.03]  \n","output_type":"stream"},{"name":"stdout","text":"→ Saved checkpoint at epoch 30\n","output_type":"stream"},{"name":"stderr","text":"Epoch [31/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.274, G=3.04] \nEpoch [32/50]: 100%|██████████| 29/29 [02:09<00:00,  4.46s/it, D=0.273, G=3.22]  \nEpoch [33/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.112, G=3.64]  \nEpoch [34/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.134, G=3.68]  \nEpoch [35/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.268, G=3.3]   \nEpoch [36/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.127, G=3.66]  \nEpoch [37/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.376, G=3.87]  \nEpoch [38/50]: 100%|██████████| 29/29 [02:09<00:00,  4.46s/it, D=0.425, G=3.09]  \nEpoch [39/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.143, G=3.63]  \nEpoch [40/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.0979, G=4.07] \n","output_type":"stream"},{"name":"stdout","text":"→ Saved checkpoint at epoch 40\n","output_type":"stream"},{"name":"stderr","text":"Epoch [41/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.397, G=3.66]  \nEpoch [42/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.329, G=2.52]  \nEpoch [43/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.337, G=2.72]  \nEpoch [44/50]: 100%|██████████| 29/29 [02:09<00:00,  4.48s/it, D=0.221, G=3]     \nEpoch [45/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.218, G=3.37]  \nEpoch [46/50]: 100%|██████████| 29/29 [02:09<00:00,  4.46s/it, D=0.209, G=3.4]   \nEpoch [47/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.249, G=3.18]  \nEpoch [48/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.27, G=3.17]   \nEpoch [49/50]: 100%|██████████| 29/29 [02:09<00:00,  4.46s/it, D=0.267, G=3.86] \nEpoch [50/50]: 100%|██████████| 29/29 [02:09<00:00,  4.47s/it, D=0.239, G=3.34]  \n","output_type":"stream"},{"name":"stdout","text":"→ Saved checkpoint at epoch 50\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 6/6 [00:18<00:00,  3.12s/it]","output_type":"stream"},{"name":"stdout","text":"\nFinal → Dice: 0.0255±0.0260,  IoU: 0.0131±0.0135\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n!python -c \"import matplotlib\" || pip install -q matplotlib\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T14:59:55.282973Z","iopub.execute_input":"2025-04-29T14:59:55.283335Z","iopub.status.idle":"2025-04-29T15:00:22.973982Z","shell.execute_reply.started":"2025-04-29T14:59:55.283302Z","shell.execute_reply":"2025-04-29T15:00:22.972922Z"}},"outputs":[{"name":"stdout","text":"2025-04-29 15:00:09.591744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-29 15:00:09.780743: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-29 15:00:09.838993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from monai.utils import first, set_determinism\nfrom monai.transforms import (\n    AsDiscrete,\n    AsDiscreted,\n    EnsureChannelFirstd,\n    Compose,\n    CropForegroundd,\n    LoadImaged,\n    Orientationd,\n    RandCropByPosNegLabeld,\n    SaveImaged,\n    ScaleIntensityRanged,\n    Spacingd,\n    Invertd,\n)\nfrom monai.handlers.utils import from_engine\nfrom monai.networks.nets import UNet\nfrom monai.networks.layers import Norm\nfrom monai.metrics import DiceMetric\nfrom monai.losses import DiceLoss\nfrom monai.inferers import sliding_window_inference\nfrom monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\nfrom monai.config import print_config\nfrom monai.apps import download_and_extract\nimport torch\nimport matplotlib.pyplot as plt\nimport tempfile\nimport shutil\nimport os\nimport glob\n\nprint_config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T15:04:56.800252Z","iopub.execute_input":"2025-04-29T15:04:56.800630Z","iopub.status.idle":"2025-04-29T15:05:03.555788Z","shell.execute_reply.started":"2025-04-29T15:04:56.800599Z","shell.execute_reply":"2025-04-29T15:05:03.554982Z"}},"outputs":[{"name":"stdout","text":"MONAI version: 1.4.1rc1+46.gb58e883c\nNumpy version: 1.26.4\nPytorch version: 2.5.1+cu121\nMONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\nMONAI rev id: b58e883c887e0f99d382807550654c44d94f47bd\nMONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n\nOptional dependencies:\nPytorch Ignite version: 0.4.11\nITK version: NOT INSTALLED or UNKNOWN VERSION.\nNibabel version: 5.3.2\nscikit-image version: 0.25.0\nscipy version: 1.13.1\nPillow version: 11.0.0\nTensorboard version: 2.17.1\ngdown version: 5.2.0\nTorchVision version: 0.20.1+cu121\ntqdm version: 4.67.1\nlmdb version: NOT INSTALLED or UNKNOWN VERSION.\npsutil version: 5.9.5\npandas version: 2.2.3\neinops version: 0.8.0\ntransformers version: 4.47.0\nmlflow version: NOT INSTALLED or UNKNOWN VERSION.\npynrrd version: NOT INSTALLED or UNKNOWN VERSION.\nclearml version: NOT INSTALLED or UNKNOWN VERSION.\n\nFor details about installing the optional dependencies, please visit:\n    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n\n","output_type":"stream"}],"execution_count":4}]}